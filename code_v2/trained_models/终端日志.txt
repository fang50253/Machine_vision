/usr/local/bin/python3
(base) fang50253@MacBook-Pro code_v2 % /usr/local/bin/python3
Python 3.13.1 (v3.13.1:06714517797, Dec  3 2024, 14:00:22) [Clang 15.0.0 (clang-1500.3.9.4)] on darwin
Type "help", "copyright", "credits" or "license" for more information.
Cmd click to launch VS Code Native REPL
>>> URLS = [
...     {
...         'name': 'éŸ³ä¹æ¬£èµ',
...         'url': 'https://jwxt.njfu.edu.cn/jsxsd/xsxkkc/ggxxkxkOper?kcid=152052&cfbs=null&jx0404id=202520262000121&xkzy=&trjf='
...     },
...     {
...         'name': 'æ¹¿åœ°ä¿æŠ¤', 
...         'url': 'https://jwxt.njfu.edu.cn/jsxsd/xsxkkc/ggxxkxkOper?kcid=382018&cfbs=null&jx0404id=202520262000220&xkzy=&trjf='
...     },
...     {
...         'name': 'å¡‘æ–™çš„å¥¥ç§˜',
...         'url': 'https://jwxt.njfu.edu.cn/jsxsd/xsxkkc/ggxxkxkOper?kcid=A714F853783B4E5AA7A15D2BF61DD1F3&cfbs=null&jx0404id=202520262000466&xkzy=&trjf='
...     },
...     {}
... ]
>>> eixt(0)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
    eixt(0)
    ^^^^
NameError: name 'eixt' is not defined
>>> exit(0)
(base) fang50253@MacBook-Pro code_v2 % conda activate fire   
(fire) fang50253@MacBook-Pro code_v2 % python -u '/Users/fang50253/De
sktop/Files/Documents/NJFU_My_Github/Machine_vision/code_v2/Train_GPU
_v5.py'
æ­£åœ¨æ£€æµ‹å¯ç”¨è®¾å¤‡...
å½“å‰æ“ä½œç³»ç»Ÿ: Darwin
æ£€æµ‹åˆ° macOS ç³»ç»Ÿ
âœ“ Apple Silicon GPU (MPS) å¯ç”¨
  æ­£åœ¨ä½¿ç”¨ MPS è®¾å¤‡è¿›è¡Œè®­ç»ƒ
ğŸš€ åˆå§‹åŒ–è®­ç»ƒç¯å¢ƒ...

==================================================
PyTorch CUDAæ”¯æŒè¯Šæ–­ (å…¼å®¹æ¨¡å¼)
==================================================
torch.cuda.is_available(): False
torch.cuda.device_count(): 0
âœ— CUDAä¸å¯ç”¨
PyTorchç‰ˆæœ¬: 2.9.0
==================================================
æ­£åœ¨æ£€æµ‹å¯ç”¨è®¾å¤‡...
å½“å‰æ“ä½œç³»ç»Ÿ: Darwin
æ£€æµ‹åˆ° macOS ç³»ç»Ÿ
âœ“ Apple Silicon GPU (MPS) å¯ç”¨
  æ­£åœ¨ä½¿ç”¨ MPS è®¾å¤‡è¿›è¡Œè®­ç»ƒ
ä½¿ç”¨è®¾å¤‡: mps

ğŸ“‹ è®­ç»ƒå‚æ•°è®¾ç½®:
è®­ç»ƒè½®æ•° (é»˜è®¤ 100): 
æ‰¹æ¬¡å¤§å° (é»˜è®¤ 16): 96
å­¦ä¹ ç‡ (é»˜è®¤ 0.001): 
æ—©åœè€å¿ƒå€¼ (é»˜è®¤ 10): 15
å›¾åƒå°ºå¯¸ (é»˜è®¤ 256x256): 
æœ€å¤§æ ·æœ¬æ•° (é»˜è®¤ 5000): 

âœ… è®­ç»ƒå‚æ•°:
  epochs: 100
  batch_size: 96
  learning_rate: 0.001
  patience: 15
  image_size: (256, 256)
  max_samples: 5000

è¯·è¾“å…¥åŒ…å«è®­ç»ƒå›¾åƒçš„æ–‡ä»¶å¤¹è·¯å¾„: '/Users/fang50253/Desktop/ç›¸æœºæ–‡ä»¶/å…¬å¼€æ•°æ®é›†/train'

ğŸ“Š å‡†å¤‡æ•°æ®é›†...
å›¾åƒæ–‡ä»¶å¤¹: /Users/fang50253/Desktop/ç›¸æœºæ–‡ä»¶/å…¬å¼€æ•°æ®é›†/train
å›¾åƒå°ºå¯¸: (256, 256)
æœ€å¤§æ ·æœ¬æ•°: 5000
æ‰¾åˆ°çš„å›¾åƒæ–‡ä»¶ç¤ºä¾‹:
  1. 0001x4d.png
  2. 0001x4m.png
  3. 0001x8.png
  4. 0002x4d.png
  5. 0002x4m.png
  ... è¿˜æœ‰ 2395 ä¸ªæ–‡ä»¶
æ‰¾åˆ° 2400 å¼ å›¾åƒï¼Œå¼€å§‹é¢„å¤„ç†...
é¢„å¤„ç†å›¾åƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2400/2400 [08:50<00:00,  4.52it/s]
é¢„å¤„ç†å®Œæˆï¼ç”Ÿæˆ 57600 ä¸ªè®­ç»ƒæ ·æœ¬
è®­ç»ƒé›†: 46080 æ ·æœ¬
éªŒè¯é›†: 11520 æ ·æœ¬

åˆå§‹åŒ–ImprovedDnCNNæ¨¡å‹ (17å±‚)...
ğŸš€ ä½¿ç”¨ Apple Silicon GPU (MPS) è¿›è¡ŒåŠ é€Ÿ
ä½¿ç”¨ Apple Silicon GPU (MPS) è¿›è¡Œè®­ç»ƒ

ğŸ¯ å¼€å§‹è®­ç»ƒ...
æ€»è½®æ•°: 100
æ‰¹æ¬¡å¤§å°: 96
å­¦ä¹ ç‡: 0.001
å¼€å§‹è®­ç»ƒæ¨¡å‹...
Epoch 1/100:   1%|â–                | 37/2880 [00:30<36:54,  1.28it/s]Epoch 1/100:   1%|â–                | 37/2880 [00:31<40:02,  1.18it/s]
Traceback (most recent call last):
  File "/Users/fang50253/Desktop/Files/Documents/NJFU_My_Github/Machine_vision/code_v2/Train_GPU_v5.py", line 71, in <module>
    model_training()
  File "/Users/fang50253/Desktop/Files/Documents/NJFU_My_Github/Machine_vision/code_v2/Train_GPU_v5.py", line 62, in model_training
    results = controller.start_training(train_loader, val_loader, params)
  File "/Users/fang50253/Desktop/Files/Documents/NJFU_My_Github/Machine_vision/code_v2/controllers/training_controller.py", line 130, in start_training
    self.train_losses, self.val_losses, best_val_loss = self.trainer.train(
  File "/Users/fang50253/Desktop/Files/Documents/NJFU_My_Github/Machine_vision/code_v2/models/trainer_model.py", line 357, in train
    train_loss += loss.item()
KeyboardInterrupt

(fire) fang50253@MacBook-Pro code_v2 % python -u '/Users/fang50253/Desktop/Files/Documents/NJFU_My_Github/Machine_vision/code_v2/Train_GPU_v5.py'
æ­£åœ¨æ£€æµ‹å¯ç”¨è®¾å¤‡...
å½“å‰æ“ä½œç³»ç»Ÿ: Darwin
æ£€æµ‹åˆ° macOS ç³»ç»Ÿ
âœ“ Apple Silicon GPU (MPS) å¯ç”¨
  æ­£åœ¨ä½¿ç”¨ MPS è®¾å¤‡è¿›è¡Œè®­ç»ƒ
ğŸš€ åˆå§‹åŒ–è®­ç»ƒç¯å¢ƒ...

==================================================
PyTorch CUDAæ”¯æŒè¯Šæ–­ (å…¼å®¹æ¨¡å¼)
==================================================
torch.cuda.is_available(): False
torch.cuda.device_count(): 0
âœ— CUDAä¸å¯ç”¨
PyTorchç‰ˆæœ¬: 2.9.0
==================================================
æ­£åœ¨æ£€æµ‹å¯ç”¨è®¾å¤‡...
å½“å‰æ“ä½œç³»ç»Ÿ: Darwin
æ£€æµ‹åˆ° macOS ç³»ç»Ÿ
âœ“ Apple Silicon GPU (MPS) å¯ç”¨
  æ­£åœ¨ä½¿ç”¨ MPS è®¾å¤‡è¿›è¡Œè®­ç»ƒ
ä½¿ç”¨è®¾å¤‡: mps

ğŸ“‹ è®­ç»ƒå‚æ•°è®¾ç½®:
è®­ç»ƒè½®æ•° (é»˜è®¤ 100): 100
æ‰¹æ¬¡å¤§å° (é»˜è®¤ 16): 96
å­¦ä¹ ç‡ (é»˜è®¤ 0.001): 
æ—©åœè€å¿ƒå€¼ (é»˜è®¤ 10): 15
å›¾åƒå°ºå¯¸ (é»˜è®¤ 256x256): 128x128
æœ€å¤§æ ·æœ¬æ•° (é»˜è®¤ 5000): 

âœ… è®­ç»ƒå‚æ•°:
  epochs: 100
  batch_size: 96
  learning_rate: 0.001
  patience: 15
  image_size: (128, 128)
  max_samples: 5000

è¯·è¾“å…¥åŒ…å«è®­ç»ƒå›¾åƒçš„æ–‡ä»¶å¤¹è·¯å¾„: '/Users/fang50253/Desktop/ç›¸æœºæ–‡ä»¶/å…¬å¼€æ•°æ®é›†/train'

ğŸ“Š å‡†å¤‡æ•°æ®é›†...
å›¾åƒæ–‡ä»¶å¤¹: /Users/fang50253/Desktop/ç›¸æœºæ–‡ä»¶/å…¬å¼€æ•°æ®é›†/train
å›¾åƒå°ºå¯¸: (128, 128)
æœ€å¤§æ ·æœ¬æ•°: 5000
æ‰¾åˆ°çš„å›¾åƒæ–‡ä»¶ç¤ºä¾‹:
  1. 0001x4d.png
  2. 0001x4m.png
  3. 0001x8.png
  4. 0002x4d.png
  5. 0002x4m.png
  ... è¿˜æœ‰ 2395 ä¸ªæ–‡ä»¶
æ‰¾åˆ° 2400 å¼ å›¾åƒï¼Œå¼€å§‹é¢„å¤„ç†...
é¢„å¤„ç†å›¾åƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2400/2400 [02:19<00:00, 17.16it/s]
é¢„å¤„ç†å®Œæˆï¼ç”Ÿæˆ 57600 ä¸ªè®­ç»ƒæ ·æœ¬
è®­ç»ƒé›†: 46080 æ ·æœ¬
éªŒè¯é›†: 11520 æ ·æœ¬

åˆå§‹åŒ–ImprovedDnCNNæ¨¡å‹ (17å±‚)...
ğŸš€ ä½¿ç”¨ Apple Silicon GPU (MPS) è¿›è¡ŒåŠ é€Ÿ
ä½¿ç”¨ Apple Silicon GPU (MPS) è¿›è¡Œè®­ç»ƒ

ğŸ¯ å¼€å§‹è®­ç»ƒ...
æ€»è½®æ•°: 100
æ‰¹æ¬¡å¤§å°: 96
å­¦ä¹ ç‡: 0.001
å¼€å§‹è®­ç»ƒæ¨¡å‹...
Epoch 1/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [08:18<00:00,  5.78it/s]
Epoch 1/100, Train Loss: 0.014011, Val Loss: 0.008280, LR: 1.00e-03
æ–°çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜: trained_models/dncnn_20251101_093202_best.pth
Epoch 2/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [08:03<00:00,  5.95it/s]
Epoch 2/100, Train Loss: 0.006099, Val Loss: 0.006403, LR: 1.00e-03
æ–°çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜: trained_models/dncnn_20251101_093202_best.pth
Epoch 3/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:55<00:00,  6.06it/s]
Epoch 3/100, Train Loss: 0.005417, Val Loss: 0.008676, LR: 1.00e-03
æ—©åœè®¡æ•°å™¨: 1/15
Epoch 4/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:49<00:00,  6.14it/s]
Epoch 4/100, Train Loss: 0.005089, Val Loss: 0.007019, LR: 1.00e-03
æ—©åœè®¡æ•°å™¨: 2/15
Epoch 5/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:43<00:00,  6.21it/s]
Epoch 5/100, Train Loss: 0.004531, Val Loss: 0.007231, LR: 1.00e-03
æ—©åœè®¡æ•°å™¨: 3/15
Epoch 6/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [08:03<00:00,  5.95it/s]
Epoch 6/100, Train Loss: 0.003513, Val Loss: 0.004541, LR: 1.00e-03
æ–°çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜: trained_models/dncnn_20251101_093202_best.pth
Epoch 7/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [08:09<00:00,  5.88it/s]
Epoch 7/100, Train Loss: 0.003407, Val Loss: 0.003779, LR: 1.00e-03
æ–°çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜: trained_models/dncnn_20251101_093202_best.pth
Epoch 8/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:47<00:00,  6.16it/s]
Epoch 8/100, Train Loss: 0.003340, Val Loss: 0.005913, LR: 1.00e-03
æ—©åœè®¡æ•°å™¨: 1/15
Epoch 9/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:38<00:00,  6.28it/s]
Epoch 9/100, Train Loss: 0.003327, Val Loss: 0.004371, LR: 1.00e-03
æ—©åœè®¡æ•°å™¨: 2/15
Epoch 10/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:37<00:00,  6.29it/s]
Epoch 10/100, Train Loss: 0.003302, Val Loss: 0.004704, LR: 1.00e-03
æ—©åœè®¡æ•°å™¨: 3/15
Epoch 11/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:46<00:00,  6.18it/s]
Epoch 11/100, Train Loss: 0.003265, Val Loss: 0.005602, LR: 1.00e-03
æ—©åœè®¡æ•°å™¨: 4/15
Epoch 12/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:57<00:00,  6.03it/s]
Epoch 12/100, Train Loss: 0.003277, Val Loss: 0.004861, LR: 1.00e-03
æ—©åœè®¡æ•°å™¨: 5/15
Epoch 13/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:35<00:00,  6.32it/s]
Epoch 13/100, Train Loss: 0.003258, Val Loss: 0.006562, LR: 5.00e-04
æ—©åœè®¡æ•°å™¨: 6/15
Epoch 14/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [29:37<00:00,  1.62it/s]
Epoch 14/100, Train Loss: 0.003022, Val Loss: 0.003866, LR: 5.00e-04
æ—©åœè®¡æ•°å™¨: 7/15
Epoch 15/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:33<00:00,  6.35it/s]
Epoch 15/100, Train Loss: 0.003024, Val Loss: 0.003411, LR: 5.00e-04
æ–°çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜: trained_models/dncnn_20251101_093202_best.pth
Epoch 16/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:33<00:00,  6.35it/s]
Epoch 16/100, Train Loss: 0.003030, Val Loss: 0.003511, LR: 5.00e-04
æ—©åœè®¡æ•°å™¨: 1/15
Epoch 17/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:30<00:00,  6.39it/s]
Epoch 17/100, Train Loss: 0.003018, Val Loss: 0.003333, LR: 5.00e-04
æ–°çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜: trained_models/dncnn_20251101_093202_best.pth
Epoch 18/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:30<00:00,  6.39it/s]
Epoch 18/100, Train Loss: 0.003033, Val Loss: 0.003807, LR: 5.00e-04
æ—©åœè®¡æ•°å™¨: 1/15
Epoch 19/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:31<00:00,  6.39it/s]
Epoch 19/100, Train Loss: 0.003023, Val Loss: 0.003496, LR: 5.00e-04
æ—©åœè®¡æ•°å™¨: 2/15
Epoch 20/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:31<00:00,  6.38it/s]
Epoch 20/100, Train Loss: 0.003020, Val Loss: 0.004359, LR: 5.00e-04
æ—©åœè®¡æ•°å™¨: 3/15
Epoch 21/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:36<00:00,  6.31it/s]
Epoch 21/100, Train Loss: 0.003012, Val Loss: 0.004294, LR: 5.00e-04
æ—©åœè®¡æ•°å™¨: 4/15
Epoch 22/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:33<00:00,  6.35it/s]
Epoch 22/100, Train Loss: 0.003016, Val Loss: 0.003914, LR: 5.00e-04
æ—©åœè®¡æ•°å™¨: 5/15
Epoch 23/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:33<00:00,  6.35it/s]
Epoch 23/100, Train Loss: 0.003010, Val Loss: 0.003960, LR: 2.50e-04
æ—©åœè®¡æ•°å™¨: 6/15
Epoch 24/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:36<00:00,  6.31it/s]
Epoch 24/100, Train Loss: 0.002881, Val Loss: 0.003126, LR: 2.50e-04
æ–°çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜: trained_models/dncnn_20251101_093202_best.pth
Epoch 25/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:35<00:00,  6.32it/s]
Epoch 25/100, Train Loss: 0.002874, Val Loss: 0.003153, LR: 2.50e-04
æ—©åœè®¡æ•°å™¨: 1/15
Epoch 26/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:37<00:00,  6.29it/s]
Epoch 26/100, Train Loss: 0.002876, Val Loss: 0.004413, LR: 2.50e-04
æ—©åœè®¡æ•°å™¨: 2/15
Epoch 27/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:38<00:00,  6.29it/s]
Epoch 27/100, Train Loss: 0.002877, Val Loss: 0.003066, LR: 2.50e-04
æ–°çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜: trained_models/dncnn_20251101_093202_best.pth
Epoch 28/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:52<00:00,  6.10it/s]
Epoch 28/100, Train Loss: 0.002873, Val Loss: 0.003507, LR: 2.50e-04
æ—©åœè®¡æ•°å™¨: 1/15
Epoch 29/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [08:03<00:00,  5.95it/s]
Epoch 29/100, Train Loss: 0.002878, Val Loss: 0.003217, LR: 2.50e-04
æ—©åœè®¡æ•°å™¨: 2/15
Epoch 30/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:52<00:00,  6.10it/s]
Epoch 30/100, Train Loss: 0.002879, Val Loss: 0.003179, LR: 2.50e-04
æ—©åœè®¡æ•°å™¨: 3/15
Epoch 31/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:53<00:00,  6.08it/s]
Epoch 31/100, Train Loss: 0.002874, Val Loss: 0.003259, LR: 2.50e-04
æ—©åœè®¡æ•°å™¨: 4/15
Epoch 32/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [08:17<00:00,  5.78it/s]
Epoch 32/100, Train Loss: 0.002870, Val Loss: 0.003126, LR: 2.50e-04
æ—©åœè®¡æ•°å™¨: 5/15
Epoch 33/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:47<00:00,  6.15it/s]
Epoch 33/100, Train Loss: 0.002879, Val Loss: 0.002949, LR: 2.50e-04
æ–°çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜: trained_models/dncnn_20251101_093202_best.pth
Epoch 34/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:48<00:00,  6.14it/s]
Epoch 34/100, Train Loss: 0.002872, Val Loss: 0.003313, LR: 2.50e-04
æ—©åœè®¡æ•°å™¨: 1/15
Epoch 35/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:51<00:00,  6.11it/s]
Epoch 35/100, Train Loss: 0.002868, Val Loss: 0.003427, LR: 2.50e-04
æ—©åœè®¡æ•°å™¨: 2/15
Epoch 36/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:51<00:00,  6.11it/s]
Epoch 36/100, Train Loss: 0.002870, Val Loss: 0.003568, LR: 2.50e-04
æ—©åœè®¡æ•°å™¨: 3/15
Epoch 37/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:47<00:00,  6.16it/s]
Epoch 37/100, Train Loss: 0.002870, Val Loss: 0.003498, LR: 2.50e-04
æ—©åœè®¡æ•°å™¨: 4/15
Epoch 38/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:45<00:00,  6.19it/s]
Epoch 38/100, Train Loss: 0.002871, Val Loss: 0.003251, LR: 2.50e-04
æ—©åœè®¡æ•°å™¨: 5/15
Epoch 39/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:46<00:00,  6.17it/s]
Epoch 39/100, Train Loss: 0.002876, Val Loss: 0.003502, LR: 1.25e-04
æ—©åœè®¡æ•°å™¨: 6/15
Epoch 40/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:54<00:00,  6.07it/s]
Epoch 40/100, Train Loss: 0.002790, Val Loss: 0.002888, LR: 1.25e-04
æ–°çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜: trained_models/dncnn_20251101_093202_best.pth
Epoch 41/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:55<00:00,  6.06it/s]
Epoch 41/100, Train Loss: 0.002789, Val Loss: 0.003361, LR: 1.25e-04
æ—©åœè®¡æ•°å™¨: 1/15
Epoch 42/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [08:15<00:00,  5.81it/s]
Epoch 42/100, Train Loss: 0.002790, Val Loss: 0.003402, LR: 1.25e-04
æ—©åœè®¡æ•°å™¨: 2/15
Epoch 43/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [08:04<00:00,  5.94it/s]
Epoch 43/100, Train Loss: 0.002782, Val Loss: 0.003028, LR: 1.25e-04
æ—©åœè®¡æ•°å™¨: 3/15
Epoch 44/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [08:19<00:00,  5.77it/s]
Epoch 44/100, Train Loss: 0.002783, Val Loss: 0.002856, LR: 1.25e-04
æ–°çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜: trained_models/dncnn_20251101_093202_best.pth
Epoch 45/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:53<00:00,  6.09it/s]
Epoch 45/100, Train Loss: 0.002783, Val Loss: 0.002929, LR: 1.25e-04
æ—©åœè®¡æ•°å™¨: 1/15
Epoch 46/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:33<00:00,  6.35it/s]
Epoch 46/100, Train Loss: 0.002782, Val Loss: 0.003161, LR: 1.25e-04
æ—©åœè®¡æ•°å™¨: 2/15
Epoch 47/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:35<00:00,  6.33it/s]
Epoch 47/100, Train Loss: 0.002786, Val Loss: 0.003222, LR: 1.25e-04
æ—©åœè®¡æ•°å™¨: 3/15
Epoch 48/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:37<00:00,  6.30it/s]
Epoch 48/100, Train Loss: 0.002780, Val Loss: 0.003158, LR: 1.25e-04
æ—©åœè®¡æ•°å™¨: 4/15
Epoch 49/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:36<00:00,  6.31it/s]
Epoch 49/100, Train Loss: 0.002782, Val Loss: 0.003054, LR: 1.25e-04
æ—©åœè®¡æ•°å™¨: 5/15
Epoch 50/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:39<00:00,  6.27it/s]
Epoch 50/100, Train Loss: 0.002780, Val Loss: 0.003031, LR: 6.25e-05
æ—©åœè®¡æ•°å™¨: 6/15
Epoch 51/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:36<00:00,  6.31it/s]
Epoch 51/100, Train Loss: 0.002731, Val Loss: 0.002901, LR: 6.25e-05
æ—©åœè®¡æ•°å™¨: 7/15
Epoch 52/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:36<00:00,  6.30it/s]
Epoch 52/100, Train Loss: 0.002734, Val Loss: 0.003055, LR: 6.25e-05
æ—©åœè®¡æ•°å™¨: 8/15
Epoch 53/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:36<00:00,  6.31it/s]
Epoch 53/100, Train Loss: 0.002729, Val Loss: 0.002785, LR: 6.25e-05
æ–°çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜: trained_models/dncnn_20251101_093202_best.pth
Epoch 54/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:38<00:00,  6.28it/s]
Epoch 54/100, Train Loss: 0.002731, Val Loss: 0.002715, LR: 6.25e-05
æ–°çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜: trained_models/dncnn_20251101_093202_best.pth
Epoch 55/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:34<00:00,  6.33it/s]
Epoch 55/100, Train Loss: 0.002727, Val Loss: 0.002859, LR: 6.25e-05
æ—©åœè®¡æ•°å™¨: 1/15
Epoch 56/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:33<00:00,  6.35it/s]
Epoch 56/100, Train Loss: 0.002733, Val Loss: 0.002843, LR: 6.25e-05
æ—©åœè®¡æ•°å™¨: 2/15
Epoch 57/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:35<00:00,  6.32it/s]
Epoch 57/100, Train Loss: 0.002726, Val Loss: 0.002884, LR: 6.25e-05
æ—©åœè®¡æ•°å™¨: 3/15
Epoch 58/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:36<00:00,  6.30it/s]
Epoch 58/100, Train Loss: 0.002727, Val Loss: 0.002845, LR: 6.25e-05
æ—©åœè®¡æ•°å™¨: 4/15
Epoch 59/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:38<00:00,  6.28it/s]
Epoch 59/100, Train Loss: 0.002727, Val Loss: 0.002837, LR: 6.25e-05
æ—©åœè®¡æ•°å™¨: 5/15
Epoch 60/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:36<00:00,  6.31it/s]
Epoch 60/100, Train Loss: 0.002725, Val Loss: 0.002813, LR: 3.13e-05
æ—©åœè®¡æ•°å™¨: 6/15
Epoch 61/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:36<00:00,  6.31it/s]
Epoch 61/100, Train Loss: 0.002698, Val Loss: 0.002757, LR: 3.13e-05
æ—©åœè®¡æ•°å™¨: 7/15
Epoch 62/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:40<00:00,  6.26it/s]
Epoch 62/100, Train Loss: 0.002694, Val Loss: 0.002742, LR: 3.13e-05
æ—©åœè®¡æ•°å™¨: 8/15
Epoch 63/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:36<00:00,  6.31it/s]
Epoch 63/100, Train Loss: 0.002694, Val Loss: 0.002706, LR: 3.13e-05
æ–°çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜: trained_models/dncnn_20251101_093202_best.pth
Epoch 64/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:33<00:00,  6.35it/s]
Epoch 64/100, Train Loss: 0.002692, Val Loss: 0.002849, LR: 3.13e-05
æ—©åœè®¡æ•°å™¨: 1/15
Epoch 65/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:34<00:00,  6.34it/s]
Epoch 65/100, Train Loss: 0.002692, Val Loss: 0.002726, LR: 3.13e-05
æ—©åœè®¡æ•°å™¨: 2/15
Epoch 66/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:29<00:00,  6.40it/s]
Epoch 66/100, Train Loss: 0.002693, Val Loss: 0.002815, LR: 3.13e-05
æ—©åœè®¡æ•°å™¨: 3/15
Epoch 67/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:28<00:00,  6.43it/s]
Epoch 67/100, Train Loss: 0.002698, Val Loss: 0.002834, LR: 3.13e-05
æ—©åœè®¡æ•°å™¨: 4/15
Epoch 68/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:28<00:00,  6.42it/s]
Epoch 68/100, Train Loss: 0.002690, Val Loss: 0.002790, LR: 3.13e-05
æ—©åœè®¡æ•°å™¨: 5/15
Epoch 69/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:28<00:00,  6.42it/s]
Epoch 69/100, Train Loss: 0.002692, Val Loss: 0.002730, LR: 1.56e-05
æ—©åœè®¡æ•°å™¨: 6/15
Epoch 70/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:27<00:00,  6.43it/s]
Epoch 70/100, Train Loss: 0.002676, Val Loss: 0.002656, LR: 1.56e-05
æ–°çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜: trained_models/dncnn_20251101_093202_best.pth
Epoch 71/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:29<00:00,  6.41it/s]
Epoch 71/100, Train Loss: 0.002674, Val Loss: 0.002678, LR: 1.56e-05
æ—©åœè®¡æ•°å™¨: 1/15
Epoch 72/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:27<00:00,  6.44it/s]
Epoch 72/100, Train Loss: 0.002671, Val Loss: 0.002665, LR: 1.56e-05
æ—©åœè®¡æ•°å™¨: 2/15
Epoch 73/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:27<00:00,  6.43it/s]
Epoch 73/100, Train Loss: 0.002675, Val Loss: 0.002675, LR: 1.56e-05
æ—©åœè®¡æ•°å™¨: 3/15
Epoch 74/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:27<00:00,  6.44it/s]
Epoch 74/100, Train Loss: 0.002671, Val Loss: 0.002667, LR: 1.56e-05
æ—©åœè®¡æ•°å™¨: 4/15
Epoch 75/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:28<00:00,  6.42it/s]
Epoch 75/100, Train Loss: 0.002671, Val Loss: 0.002706, LR: 1.56e-05
æ—©åœè®¡æ•°å™¨: 5/15
Epoch 76/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:27<00:00,  6.43it/s]
Epoch 76/100, Train Loss: 0.002669, Val Loss: 0.002638, LR: 1.56e-05
æ–°çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜: trained_models/dncnn_20251101_093202_best.pth
Epoch 77/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:30<00:00,  6.39it/s]
Epoch 77/100, Train Loss: 0.002671, Val Loss: 0.002671, LR: 1.56e-05
æ—©åœè®¡æ•°å™¨: 1/15
Epoch 78/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:27<00:00,  6.43it/s]
Epoch 78/100, Train Loss: 0.002668, Val Loss: 0.002641, LR: 1.56e-05
æ—©åœè®¡æ•°å™¨: 2/15
Epoch 79/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:29<00:00,  6.41it/s]
Epoch 79/100, Train Loss: 0.002668, Val Loss: 0.002655, LR: 1.56e-05
æ—©åœè®¡æ•°å™¨: 3/15
Epoch 80/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:44<00:00,  6.20it/s]
Epoch 80/100, Train Loss: 0.002668, Val Loss: 0.002682, LR: 1.56e-05
æ—©åœè®¡æ•°å™¨: 4/15
Epoch 81/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:33<00:00,  6.36it/s]
Epoch 81/100, Train Loss: 0.002670, Val Loss: 0.002693, LR: 1.56e-05
æ—©åœè®¡æ•°å™¨: 5/15
Epoch 82/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:38<00:00,  6.29it/s]
Epoch 82/100, Train Loss: 0.002673, Val Loss: 0.002721, LR: 7.81e-06
æ—©åœè®¡æ•°å™¨: 6/15
Epoch 83/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:32<00:00,  6.36it/s]
Epoch 83/100, Train Loss: 0.002657, Val Loss: 0.002625, LR: 7.81e-06
æ–°çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜: trained_models/dncnn_20251101_093202_best.pth
Epoch 84/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:33<00:00,  6.35it/s]
Epoch 84/100, Train Loss: 0.002659, Val Loss: 0.002641, LR: 7.81e-06
æ—©åœè®¡æ•°å™¨: 1/15
Epoch 85/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:30<00:00,  6.39it/s]
Epoch 85/100, Train Loss: 0.002656, Val Loss: 0.002636, LR: 7.81e-06
æ—©åœè®¡æ•°å™¨: 2/15
Epoch 86/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:31<00:00,  6.38it/s]
Epoch 86/100, Train Loss: 0.002661, Val Loss: 0.002632, LR: 7.81e-06
æ—©åœè®¡æ•°å™¨: 3/15
Epoch 87/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:36<00:00,  6.30it/s]
Epoch 87/100, Train Loss: 0.002658, Val Loss: 0.002643, LR: 7.81e-06
æ—©åœè®¡æ•°å™¨: 4/15
Epoch 88/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:34<00:00,  6.33it/s]
Epoch 88/100, Train Loss: 0.002655, Val Loss: 0.002626, LR: 7.81e-06
æ—©åœè®¡æ•°å™¨: 5/15
Epoch 89/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:36<00:00,  6.31it/s]
Epoch 89/100, Train Loss: 0.002661, Val Loss: 0.002633, LR: 3.91e-06
æ—©åœè®¡æ•°å™¨: 6/15
Epoch 90/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:32<00:00,  6.36it/s]
Epoch 90/100, Train Loss: 0.002654, Val Loss: 0.002613, LR: 3.91e-06
æ–°çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜: trained_models/dncnn_20251101_093202_best.pth
Epoch 91/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:35<00:00,  6.33it/s]
Epoch 91/100, Train Loss: 0.002651, Val Loss: 0.002620, LR: 3.91e-06
æ—©åœè®¡æ•°å™¨: 1/15
Epoch 92/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:30<00:00,  6.40it/s]
Epoch 92/100, Train Loss: 0.002650, Val Loss: 0.002618, LR: 3.91e-06
æ—©åœè®¡æ•°å™¨: 2/15
Epoch 93/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:33<00:00,  6.36it/s]
Epoch 93/100, Train Loss: 0.002652, Val Loss: 0.002615, LR: 3.91e-06
æ—©åœè®¡æ•°å™¨: 3/15
Epoch 94/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:34<00:00,  6.34it/s]
Epoch 94/100, Train Loss: 0.002652, Val Loss: 0.002618, LR: 3.91e-06
æ—©åœè®¡æ•°å™¨: 4/15
Epoch 95/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:34<00:00,  6.34it/s]
Epoch 95/100, Train Loss: 0.002652, Val Loss: 0.002618, LR: 3.91e-06
æ—©åœè®¡æ•°å™¨: 5/15
Epoch 96/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:32<00:00,  6.36it/s]
Epoch 96/100, Train Loss: 0.002653, Val Loss: 0.002614, LR: 1.95e-06
æ—©åœè®¡æ•°å™¨: 6/15
Epoch 97/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:36<00:00,  6.31it/s]
Epoch 97/100, Train Loss: 0.002651, Val Loss: 0.002620, LR: 1.95e-06
æ—©åœè®¡æ•°å™¨: 7/15
Epoch 98/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:35<00:00,  6.32it/s]
Epoch 98/100, Train Loss: 0.002650, Val Loss: 0.002614, LR: 1.95e-06
æ—©åœè®¡æ•°å™¨: 8/15
Epoch 99/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:36<00:00,  6.31it/s]
Epoch 99/100, Train Loss: 0.002648, Val Loss: 0.002611, LR: 1.95e-06
æ–°çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜: trained_models/dncnn_20251101_093202_best.pth
Epoch 100/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2880/2880 [07:35<00:00,  6.32it/s]
Epoch 100/100, Train Loss: 0.002648, Val Loss: 0.002613, LR: 1.95e-06
æ—©åœè®¡æ•°å™¨: 1/15

è®­ç»ƒå®Œæˆï¼æ€»è€—æ—¶: 842.33 åˆ†é’Ÿ
æœ€ä½³éªŒè¯æŸå¤±: 0.002611

ğŸ“ˆ è®­ç»ƒå®Œæˆ!
è®­ç»ƒè½®æ•°: 100
æœ€ä½³éªŒè¯æŸå¤±: 0.002611
2025-11-01 23:34:40.688 python[21774:7417327] The class 'NSSavePanel' overrides the method identifier.  This method is implemented by class 'NSWindow'
Error plotting loss curves: 'TrainingController' object has no attribute '_save_loss_plot'

ğŸ“Š è®­ç»ƒç»Ÿè®¡:
æœ€ç»ˆè®­ç»ƒæŸå¤±: 0.002648
æœ€ç»ˆéªŒè¯æŸå¤±: 0.002613
è®­ç»ƒæŸå¤±æ”¹è¿›: 81.1%
éªŒè¯æŸå¤±æ”¹è¿›: 68.4%
è®­ç»ƒæŸå¤±èŒƒå›´: 0.002648 - 0.014011
éªŒè¯æŸå¤±èŒƒå›´: 0.002611 - 0.008676
(fire) fang50253@MacBook-Pro code_v2 % 