import torch
import os
import cv2
from datetime import datetime
import matplotlib.pyplot as plt
import numpy as np

# è§†å›¾å±‚å¯¼å…¥
from views.cli_view import CLIView

# æ§åˆ¶å™¨å±‚å¯¼å…¥
from controllers.denoise_controller import DenoiseController
from controllers.batch_controller import BatchController
from controllers.sharpening_controller import SharpeningController

# å·¥å…·å‡½æ•°å¯¼å…¥
from utils.image_utils import get_model_path

# å¦‚æœéœ€è¦ç›´æ¥ä½¿ç”¨æ¨¡å‹ç±»
from models.denoiser_models import ImprovedDnCNN
from models.traditional_denoiser import TraditionalDenoiser, AdvancedDenoiser
from models.image_sharpener import ImageSharpener
from models.trainer_model import EarlyStopping, AdvancedDenoisingDataset, ModelTrainer

# å¦‚æœéœ€è¦è®¾å¤‡å·¥å…·
from utils.device_utils import setup_device, check_pytorch_cuda_support

from config import NUM_LAYERS

class TrainingController:
    """è®­ç»ƒæ§åˆ¶å™¨ - æ·»åŠ æŸå¤±æ›²çº¿æ˜¾ç¤º"""
    
    def __init__(self):
        self.model = None
        self.trainer = None
        self.device = setup_device()
        self.train_losses = []
        self.val_losses = []
    
    def setup_environment(self):
        """è®¾ç½®è®­ç»ƒç¯å¢ƒ"""
        print("ğŸš€ åˆå§‹åŒ–è®­ç»ƒç¯å¢ƒ...")
        check_pytorch_cuda_support()
        print(f"ä½¿ç”¨è®¾å¤‡: {self.device}")
    
    def get_training_parameters(self):
        """è·å–è®­ç»ƒå‚æ•°"""
        print("\nğŸ“‹ è®­ç»ƒå‚æ•°è®¾ç½®:")
        
        params = {
            'epochs': 100,
            'batch_size': 16,
            'learning_rate': 0.001,
            'patience': 10,
            'image_size': (256, 256),
            'max_samples': 5000
        }
        
        try:
            params['epochs'] = int(input(f"è®­ç»ƒè½®æ•° (é»˜è®¤ {params['epochs']}): ") or params['epochs'])
            params['batch_size'] = int(input(f"æ‰¹æ¬¡å¤§å° (é»˜è®¤ {params['batch_size']}): ") or params['batch_size'])
            params['learning_rate'] = float(input(f"å­¦ä¹ ç‡ (é»˜è®¤ {params['learning_rate']}): ") or params['learning_rate'])
            params['patience'] = int(input(f"æ—©åœè€å¿ƒå€¼ (é»˜è®¤ {params['patience']}): ") or params['patience'])
            
            size_input = input(f"å›¾åƒå°ºå¯¸ (é»˜è®¤ {params['image_size'][0]}x{params['image_size'][1]}): ") or f"{params['image_size'][0]}x{params['image_size'][1]}"
            if 'x' in size_input:
                w, h = map(int, size_input.split('x'))
                params['image_size'] = (h, w)  # OpenCV ä½¿ç”¨ (height, width)
            
            params['max_samples'] = int(input(f"æœ€å¤§æ ·æœ¬æ•° (é»˜è®¤ {params['max_samples']}): ") or params['max_samples'])
            
        except ValueError as e:
            print(f"å‚æ•°è¾“å…¥é”™è¯¯ï¼Œä½¿ç”¨é»˜è®¤å€¼: {e}")
        
        print("\nâœ… è®­ç»ƒå‚æ•°:")
        for key, value in params.items():
            print(f"  {key}: {value}")
        
        return params
    
    def prepare_datasets(self, image_folder, image_size, max_samples):
        """å‡†å¤‡æ•°æ®é›†"""
        print(f"\nğŸ“Š å‡†å¤‡æ•°æ®é›†...")
        print(f"å›¾åƒæ–‡ä»¶å¤¹: {image_folder}")
        print(f"å›¾åƒå°ºå¯¸: {image_size}")
        print(f"æœ€å¤§æ ·æœ¬æ•°: {max_samples}")
        
        # åˆ›å»ºæ•°æ®é›†
        dataset = AdvancedDenoisingDataset(
            image_folder=image_folder,
            target_size=image_size,
            max_samples=max_samples
        )
        
        # åˆ†å‰²è®­ç»ƒé›†å’ŒéªŒè¯é›†
        train_size = int(0.8 * len(dataset))
        val_size = len(dataset) - train_size
        train_dataset, val_dataset = torch.utils.data.random_split(
            dataset, [train_size, val_size]
        )
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_loader = torch.utils.data.DataLoader(
            train_dataset, batch_size=16, shuffle=True, num_workers=0
        )
        val_loader = torch.utils.data.DataLoader(
            val_dataset, batch_size=16, shuffle=False, num_workers=0
        )
        
        print(f"è®­ç»ƒé›†: {len(train_dataset)} æ ·æœ¬")
        print(f"éªŒè¯é›†: {len(val_dataset)} æ ·æœ¬")
        
        return train_loader, val_loader
    
    def initialize_model(self, num_layers=17):
        """åˆå§‹åŒ–æ¨¡å‹"""
        print(f"\nåˆå§‹åŒ–ImprovedDnCNNæ¨¡å‹ ({num_layers}å±‚)...")
        self.model = ImprovedDnCNN(channels=3, num_layers=num_layers, num_features=64)
        self.trainer = ModelTrainer(self.model, "trained_models")
        return self.model
    
    def start_training(self, train_loader, val_loader, params):
        """å¼€å§‹è®­ç»ƒ"""
        print(f"\nğŸ¯ å¼€å§‹è®­ç»ƒ...")
        print(f"æ€»è½®æ•°: {params['epochs']}")
        print(f"æ‰¹æ¬¡å¤§å°: {params['batch_size']}")
        print(f"å­¦ä¹ ç‡: {params['learning_rate']}")
        
        # å¼€å§‹è®­ç»ƒå¹¶è·å–æŸå¤±å†å²
        self.train_losses, self.val_losses, best_val_loss = self.trainer.train(
            train_loader=train_loader,
            val_loader=val_loader,
            epochs=params['epochs'],
            lr=params['learning_rate'],
            patience=params['patience']
        )
        
        return {
            'train_losses': self.train_losses,
            'val_losses': self.val_losses,
            'best_val_loss': best_val_loss,
            'epochs_trained': len(self.train_losses)
        }
    
    def display_training_results(self, results):
        """æ˜¾ç¤ºè®­ç»ƒç»“æœå’ŒæŸå¤±æ›²çº¿"""
        print(f"\nğŸ“ˆ è®­ç»ƒå®Œæˆ!")
        print(f"è®­ç»ƒè½®æ•°: {results['epochs_trained']}")
        print(f"æœ€ä½³éªŒè¯æŸå¤±: {results['best_val_loss']:.6f}")
        
        # æ˜¾ç¤ºæŸå¤±æ›²çº¿
        self._plot_loss_curves(results)
        
        # æ˜¾ç¤ºè®­ç»ƒç»Ÿè®¡
        self._display_training_stats(results)
    
    def _plot_loss_curves(self, results):
        """ç»˜åˆ¶æŸå¤±æ›²çº¿"""
        try:
            plt.figure(figsize=(12, 8))
            
            # ç»˜åˆ¶è®­ç»ƒå’ŒéªŒè¯æŸå¤±
            epochs = range(1, len(results['train_losses']) + 1)
            
            plt.subplot(2, 1, 1)
            plt.plot(epochs, results['train_losses'], 'b-', label='è®­ç»ƒæŸå¤±', linewidth=2)
            plt.plot(epochs, results['val_losses'], 'r-', label='éªŒè¯æŸå¤±', linewidth=2)
            plt.title('è®­ç»ƒå’ŒéªŒè¯æŸå¤±æ›²çº¿', fontsize=14, fontweight='bold')
            plt.xlabel('è½®æ¬¡')
            plt.ylabel('æŸå¤± (MSE)')
            plt.legend()
            plt.grid(True, alpha=0.3)
            
            # ç»˜åˆ¶å¯¹æ•°å°ºåº¦æŸå¤±
            plt.subplot(2, 1, 2)
            plt.semilogy(epochs, results['train_losses'], 'b-', label='train loss', linewidth=2, alpha=0.7)
            plt.semilogy(epochs, results['val_losses'], 'r-', label='valid loss', linewidth=2, alpha=0.7)
            plt.title('å¯¹æ•°å°ºåº¦æŸå¤±æ›²çº¿', fontsize=14, fontweight='bold')
            plt.xlabel('è½®æ¬¡')
            plt.ylabel('æŸå¤± (log MSE)')
            plt.legend()
            plt.grid(True, alpha=0.3)
            
            plt.tight_layout()
            plt.show()
            
            # ä¿å­˜æŸå¤±æ›²çº¿
            self._save_loss_plot(results)
            
        except Exception as e:
            print(f"ç»˜åˆ¶æŸå¤±æ›²çº¿æ—¶å‡ºé”™: {e}")
    
    def _plot_loss_curves(self, results):
        """Plot loss curves"""
        try:
            plt.figure(figsize=(12, 8))
            
            # Plot training and validation losses
            epochs = range(1, len(results['train_losses']) + 1)
            
            plt.subplot(2, 1, 1)
            plt.plot(epochs, results['train_losses'], 'b-', label='Training Loss', linewidth=2)
            plt.plot(epochs, results['val_losses'], 'r-', label='Validation Loss', linewidth=2)
            plt.title('Training and Validation Loss Curves', fontsize=14, fontweight='bold')
            plt.xlabel('Epochs')
            plt.ylabel('Loss (MSE)')
            plt.legend()
            plt.grid(True, alpha=0.3)
            
            # Plot log-scale losses
            plt.subplot(2, 1, 2)
            plt.semilogy(epochs, results['train_losses'], 'b-', label='Training Loss', linewidth=2, alpha=0.7)
            plt.semilogy(epochs, results['val_losses'], 'r-', label='Validation Loss', linewidth=2, alpha=0.7)
            plt.title('Log-Scale Loss Curves', fontsize=14, fontweight='bold')
            plt.xlabel('Epochs')
            plt.ylabel('Loss (log MSE)')
            plt.legend()
            plt.grid(True, alpha=0.3)
            
            plt.tight_layout()
            plt.show()
            
            # Save loss plot
            self._save_loss_plot(results)
        
        except Exception as e:
            print(f"Error plotting loss curves: {e}")
    
    def _display_training_stats(self, results):
        """æ˜¾ç¤ºè®­ç»ƒç»Ÿè®¡ä¿¡æ¯"""
        train_losses = results['train_losses']
        val_losses = results['val_losses']
        
        print(f"\nğŸ“Š è®­ç»ƒç»Ÿè®¡:")
        print(f"æœ€ç»ˆè®­ç»ƒæŸå¤±: {train_losses[-1]:.6f}")
        print(f"æœ€ç»ˆéªŒè¯æŸå¤±: {val_losses[-1]:.6f}")
        
        # è®¡ç®—æ”¹è¿›ç¨‹åº¦
        initial_train_loss = train_losses[0] if train_losses else 0
        initial_val_loss = val_losses[0] if val_losses else 0
        
        if initial_train_loss > 0:
            train_improvement = (initial_train_loss - train_losses[-1]) / initial_train_loss * 100
            print(f"è®­ç»ƒæŸå¤±æ”¹è¿›: {train_improvement:.1f}%")
        
        if initial_val_loss > 0:
            val_improvement = (initial_val_loss - val_losses[-1]) / initial_val_loss * 100
            print(f"éªŒè¯æŸå¤±æ”¹è¿›: {val_improvement:.1f}%")
        
        # æ˜¾ç¤ºæŸå¤±èŒƒå›´
        if train_losses:
            print(f"è®­ç»ƒæŸå¤±èŒƒå›´: {min(train_losses):.6f} - {max(train_losses):.6f}")
        if val_losses:
            print(f"éªŒè¯æŸå¤±èŒƒå›´: {min(val_losses):.6f} - {max(val_losses):.6f}")

def model_training():
    """æ¨¡å‹è®­ç»ƒæ¨¡å¼"""
    try:
        controller = TrainingController()
        
        # è®¾ç½®ç¯å¢ƒ
        controller.setup_environment()
        
        # è·å–è®­ç»ƒå‚æ•°
        params = controller.get_training_parameters()
        
        # è·å–å›¾åƒæ–‡ä»¶å¤¹
        image_folder = input("\nè¯·è¾“å…¥åŒ…å«è®­ç»ƒå›¾åƒçš„æ–‡ä»¶å¤¹è·¯å¾„: ").strip().strip('"\'')
        if not os.path.exists(image_folder):
            print(f"é”™è¯¯ï¼šæ–‡ä»¶å¤¹ '{image_folder}' ä¸å­˜åœ¨ï¼")
            return
        
        # å‡†å¤‡æ•°æ®
        train_loader, val_loader = controller.prepare_datasets(
            image_folder, 
            params['image_size'], 
            params['max_samples']
        )
        
        # åˆå§‹åŒ–æ¨¡å‹
        controller.initialize_model(NUM_LAYERS)
        
        # å¼€å§‹è®­ç»ƒ
        results = controller.start_training(train_loader, val_loader, params)
        
        # æ˜¾ç¤ºç»“æœå’ŒæŸå¤±æ›²çº¿
        controller.display_training_results(results)
        
    except Exception as e:
        print(f"è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºé”™: {e}")

if __name__ == "__main__":
    model_training()