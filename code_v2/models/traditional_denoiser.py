import cv2
import numpy as np
from skimage.metrics import structural_similarity as ssim
import pywt
from typing import Dict, List, Tuple
import torch
import os
import platform
from config import NUM_LAYERS
from models.image_sharpener import ImageSharpener

class TraditionalDenoiser:
    """ä¼ ç»Ÿå»å™ªæ–¹æ³• - å®Œæ•´ä¿®å¤ç‰ˆæœ¬"""
    
    def wavelet_denoise_robust(self, image):
        """å°æ³¢å»å™ª - ä¿®å¤å½¢çŠ¶é—®é¢˜"""
        try:
            if len(image.shape) == 3:
                # å½©è‰²å›¾åƒ - åˆ†åˆ«å¤„ç†æ¯ä¸ªé€šé“
                denoised = np.zeros_like(image, dtype=np.float32)
                for i in range(3):
                    channel_denoised = self._wavelet_denoise_channel(image[:,:,i])
                    # ç¡®ä¿å½¢çŠ¶åŒ¹é…
                    if channel_denoised.shape == image[:,:,i].shape:
                        denoised[:,:,i] = channel_denoised
                    else:
                        # å¦‚æœä¸åŒ¹é…ï¼Œä½¿ç”¨ä¸­å€¼æ»¤æ³¢
                        denoised[:,:,i] = cv2.medianBlur(image[:,:,i], 3)
                return np.clip(denoised, 0, 255).astype(np.uint8)
            else:
                # ç°åº¦å›¾åƒ
                denoised = self._wavelet_denoise_channel(image)
                if denoised.shape == image.shape:
                    return np.clip(denoised, 0, 255).astype(np.uint8)
                else:
                    return cv2.medianBlur(image, 3)
        except Exception as e:
            print(f"å°æ³¢å»å™ªå¤±è´¥: {e}, ä½¿ç”¨ä¸­å€¼æ»¤æ³¢æ›¿ä»£")
            return cv2.medianBlur(image, 5)
    
    def _wavelet_denoise_channel(self, channel):
        """å•é€šé“å°æ³¢å»å™ª"""
        try:
            # ç¡®ä¿è¾“å…¥æ˜¯2D
            if len(channel.shape) > 2:
                channel = channel.squeeze()
            
            # ä½¿ç”¨å°æ³¢å˜æ¢
            coeffs = pywt.wavedec2(channel.astype(np.float32), 'db8', level=2)
            
            # è®¡ç®—é˜ˆå€¼
            detail_coeffs = coeffs[1:]
            if detail_coeffs:
                std_dev = np.std([np.std(c) for c in detail_coeffs if hasattr(c, '__iter__')])
                threshold = std_dev * 0.1
            else:
                threshold = 10.0
            
            # åº”ç”¨è½¯é˜ˆå€¼
            new_coeffs = [coeffs[0]]  # ä¿ç•™è¿‘ä¼¼ç³»æ•°
            for coeff in coeffs[1:]:
                if isinstance(coeff, tuple):
                    # ç»†èŠ‚ç³»æ•°
                    coeff_thresh = tuple(pywt.threshold(c, threshold, mode='soft') for c in coeff)
                    new_coeffs.append(coeff_thresh)
                else:
                    new_coeffs.append(coeff)
            
            # å°æ³¢é‡æ„
            denoised = pywt.waverec2(new_coeffs, 'db8')
            
            # ç¡®ä¿è¾“å‡ºå½¢çŠ¶ä¸è¾“å…¥ä¸€è‡´
            if denoised.shape != channel.shape:
                denoised = cv2.resize(denoised, (channel.shape[1], channel.shape[0]))
            
            return denoised
            
        except Exception as e:
            raise Exception(f"å•é€šé“å°æ³¢å»å™ªå¤±è´¥: {e}")
    
    def bilateral_denoise_advanced(self, image, noise_types=None, intensities=None):
        """åŒè¾¹æ»¤æ³¢å»å™ª - ä¿®å¤æ–¹æ³•å"""
        return self.bilateral_denoise_adaptive(image, noise_types, intensities)
    
    def bilateral_denoise_adaptive(self, image, noise_types=None, intensities=None):
        """åŒè¾¹æ»¤æ³¢å»å™ª - è‡ªé€‚åº”å‚æ•°"""
        # æ ¹æ®å™ªå£°ç±»å‹è°ƒæ•´å‚æ•°
        if noise_types and intensities:
            if 'salt_pepper' in noise_types:
                d = 9
                sigma_color = 50
                sigma_space = 50
            else:
                d = 7
                sigma_color = 35
                sigma_space = 35
        else:
            d = 7
            sigma_color = 35
            sigma_space = 35
        
        print(f"è‡ªé€‚åº”åŒè¾¹æ»¤æ³¢å‚æ•°: d={d}, sigma_color={sigma_color}, sigma_space={sigma_space}")
        
        try:
            return cv2.bilateralFilter(image, d, sigma_color, sigma_space)
        except Exception as e:
            print(f"åŒè¾¹æ»¤æ³¢å¤±è´¥: {e}, ä½¿ç”¨é«˜æ–¯æ»¤æ³¢æ›¿ä»£")
            return cv2.GaussianBlur(image, (5, 5), 0)
    
    def bilateral_denoise_basic(self, image):
        """åŸºç¡€åŒè¾¹æ»¤æ³¢"""
        return cv2.bilateralFilter(image, 9, 75, 75)
    
    def wavelet_bilateral_hybrid(self, image):
        """å°æ³¢åŒè¾¹æ··åˆå»å™ª"""
        try:
            # å…ˆå°æ³¢å»å™ª
            wavelet_result = self.wavelet_denoise_robust(image)
            # å†åŒè¾¹æ»¤æ³¢
            bilateral_result = self.bilateral_denoise_basic(wavelet_result)
            return bilateral_result
        except Exception as e:
            print(f"æ··åˆå»å™ªå¤±è´¥: {e}, ä½¿ç”¨ä¸­å€¼æ»¤æ³¢æ›¿ä»£")
            return cv2.medianBlur(image, 5)

def calculate_psnr(original: np.ndarray, processed: np.ndarray) -> float:
    """è®¡ç®— PSNR (å³°å€¼ä¿¡å™ªæ¯”) - ä¿®å¤ç‰ˆæœ¬"""
    try:
        # ç¡®ä¿å›¾åƒæ•°æ®ç±»å‹å’Œå½¢çŠ¶ä¸€è‡´
        if original.shape != processed.shape:
            processed = cv2.resize(processed, (original.shape[1], original.shape[0]))
        
        if original.dtype != processed.dtype:
            processed = processed.astype(original.dtype)
        
        # è½¬æ¢ä¸º float è¿›è¡Œè®¡ç®—
        original_float = original.astype(np.float64)
        processed_float = processed.astype(np.float64)
        
        # è®¡ç®— MSE
        mse = np.mean((original_float - processed_float) ** 2)
        
        if mse == 0:
            return float('inf')
        
        # è®¡ç®— PSNR
        max_pixel = 255.0
        psnr = 20 * np.log10(max_pixel / np.sqrt(mse))
        return max(0.0, psnr)  # ç¡®ä¿éè´Ÿ
    
    except Exception as e:
        print(f"PSNR è®¡ç®—é”™è¯¯: {e}")
        return 0.0

def calculate_ssim(original: np.ndarray, processed: np.ndarray) -> float:
    """è®¡ç®— SSIM (ç»“æ„ç›¸ä¼¼æ€§æŒ‡æ•°) - ä¿®å¤ç‰ˆæœ¬"""
    try:
        # ç¡®ä¿å›¾åƒæ•°æ®ç±»å‹å’Œå½¢çŠ¶ä¸€è‡´
        if original.shape != processed.shape:
            processed = cv2.resize(processed, (original.shape[1], original.shape[0]))
        
        if original.dtype != processed.dtype:
            processed = processed.astype(original.dtype)
        
        # ç¡®ä¿æ•°æ®èŒƒå›´æ­£ç¡®
        if original.max() > 1.0:
            original = original.astype(np.float64) / 255.0
        if processed.max() > 1.0:
            processed = processed.astype(np.float64) / 255.0
        
        # å¯¹äºå½©è‰²å›¾åƒ
        if len(original.shape) == 3 and original.shape[2] == 3:
            ssim_values = []
            for i in range(3):
                try:
                    channel_ssim = ssim(
                        original[:, :, i],
                        processed[:, :, i],
                        data_range=1.0,
                        win_size=7,  # ä½¿ç”¨å›ºå®šçª—å£å¤§å°
                        channel_axis=None
                    )
                    ssim_values.append(channel_ssim)
                except:
                    ssim_values.append(0.0)
            
            if ssim_values:
                return float(np.mean(ssim_values))
            else:
                return 0.0
        else:
            # ç°åº¦å›¾åƒ
            try:
                return ssim(
                    original,
                    processed,
                    data_range=1.0,
                    win_size=7,
                    channel_axis=None
                )
            except:
                return 0.0
    
    except Exception as e:
        print(f"SSIM è®¡ç®—é”™è¯¯: {e}")
        return 0.0

class AdvancedDenoiser:
    """é«˜çº§å»å™ªå™¨ - ä¿®å¤ç‰ˆæœ¬"""
    

    def __init__(self, model_path: str = None, device: str = "auto"):
        self.device = self._setup_device(device)
        self.model = None
        self.traditional_denoiser = TraditionalDenoiser()
        self.image_sharpener = ImageSharpener()  # æ·»åŠ é”åŒ–å™¨
        
        self._print_device_info()
        
        if model_path and os.path.exists(model_path):
            self.load_model(model_path)
        else:
            print("â„¹ï¸ ä½¿ç”¨ä¼ ç»Ÿå»å™ªæ–¹æ³•")
    
    def _setup_device(self, device_preference):
        """è®¾ç½®è®¾å¤‡"""
        system = platform.system()
        
        if device_preference == "mps" and system == "Darwin":
            return self._get_mps_device()
        elif device_preference == "cuda":
            return self._get_cuda_device()
        elif device_preference == "cpu":
            return torch.device("cpu")
        else:  # auto
            if system == "Darwin":
                return self._get_mps_device()
            else:
                return self._get_cuda_device()
    
    def _get_mps_device(self):
        """è·å– MPS è®¾å¤‡"""
        if (hasattr(torch.backends, 'mps') and 
            torch.backends.mps.is_available()):
            try:
                test_tensor = torch.tensor([1.0], device='mps')
                _ = test_tensor * 2
                print("ğŸš€ ä½¿ç”¨ Apple Silicon GPU (MPS)")
                return torch.device("mps")
            except Exception as e:
                print(f"âš ï¸ MPS æµ‹è¯•å¤±è´¥: {e}")
        print("âš ï¸ ä½¿ç”¨ CPU")
        return torch.device("cpu")
    
    def _get_cuda_device(self):
        """è·å– CUDA è®¾å¤‡"""
        if torch.cuda.is_available():
            try:
                test_tensor = torch.tensor([1.0]).cuda()
                if test_tensor.is_cuda:
                    print("ğŸš€ ä½¿ç”¨ NVIDIA GPU")
                    return torch.device("cuda")
            except Exception as e:
                print(f"âš ï¸ CUDA æµ‹è¯•å¤±è´¥: {e}")
        print("âš ï¸ ä½¿ç”¨ CPU")
        return torch.device("cpu")
    
    def _print_device_info(self):
        """æ‰“å°è®¾å¤‡ä¿¡æ¯"""
        print(f"ğŸ¯ å½“å‰è®¾å¤‡: {self.device}")
    
    def load_model(self, model_path):
        """åŠ è½½æ¨¡å‹"""
        try:
            from models.dncnn import DnCNN
            self.model = DnCNN(channels=3, num_layers=NUM_LAYERS)
            
            print(f"ğŸ“¦ åŠ è½½æ¨¡å‹: {model_path}")
            state_dict = torch.load(model_path, map_location='cpu')
            
            # æ¸…ç†çŠ¶æ€å­—å…¸
            state_dict = self._clean_state_dict(state_dict)
            
            self.model.load_state_dict(state_dict, strict=False)
            self.model.to(self.device)
            self.model.eval()
            
            print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
            return True
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            self.model = None
            return False
    
    def _clean_state_dict(self, state_dict):
        """æ¸…ç†çŠ¶æ€å­—å…¸"""
        from collections import OrderedDict
        
        if all(key.startswith('module.') for key in state_dict.keys()):
            new_state_dict = OrderedDict()
            for k, v in state_dict.items():
                name = k[7:]
                new_state_dict[name] = v
            return new_state_dict
        
        return state_dict
    
    def deep_learning_denoise(self, image):
        """æ·±åº¦å­¦ä¹ å»å™ª"""
        if self.model is None:
            return self.traditional_denoiser.bilateral_denoise_basic(image)
        
        try:
            import time
            start_time = time.time()
            
            # é¢„å¤„ç†
            image_tensor = self._preprocess_image(image)
            
            # æ¨ç†
            with torch.no_grad():
                noise_pred = self.model(image_tensor)
                output_tensor = image_tensor - noise_pred
            
            # åå¤„ç†
            output_image = self._postprocess_output(output_tensor, image.shape)
            
            inference_time = time.time() - start_time
            print(f"âš¡ æ·±åº¦å­¦ä¹ æ¨ç†: {inference_time:.3f}s")
            
            return output_image
            
        except Exception as e:
            print(f"âŒ æ·±åº¦å­¦ä¹ å¤±è´¥: {e}")
            return self.traditional_denoiser.bilateral_denoise_basic(image)
    
    def _preprocess_image(self, image):
        """é¢„å¤„ç†å›¾åƒ"""
        if image.dtype != np.float32:
            image = image.astype(np.float32)
        
        if image.max() > 1.0:
            image = image / 255.0
        
        if len(image.shape) == 3:
            image_tensor = torch.from_numpy(image.transpose(2, 0, 1))
        else:
            image_tensor = torch.from_numpy(image).unsqueeze(0)
        
        image_tensor = image_tensor.unsqueeze(0).to(self.device)
        return image_tensor
    
    def _postprocess_output(self, output_tensor, original_shape):
        """åå¤„ç†è¾“å‡º"""
        output = output_tensor.squeeze(0).cpu().numpy()
        output = np.clip(output * 255.0, 0, 255).astype(np.uint8)
        
        if len(output.shape) == 3:
            output = output.transpose(1, 2, 0)
        
        # ç¡®ä¿è¾“å‡ºå½¢çŠ¶ä¸è¾“å…¥ä¸€è‡´
        if output.shape != original_shape:
            output = cv2.resize(output, (original_shape[1], original_shape[0]))
        
        return output
    
    def hybrid_denoise_v1(self, image):
        """æ··åˆå»å™ªæ–¹æ³•1"""
        dl_result = self.traditional_denoiser.deep_learning_denoise(image)
        return self.wavelet_bilateral_hybrid(dl_result)
    
    
    
    def _initialize_sharpener(self):
        """åˆå§‹åŒ–å›¾åƒé”åŒ–å™¨"""
        try:
            # ä» models åŒ…å¯¼å…¥ ImageSharpener
            from models.image_sharpener import ImageSharpener
            print("âœ… å›¾åƒé”åŒ–å™¨åˆå§‹åŒ–æˆåŠŸ")
            return ImageSharpener()
        except ImportError as e:
            print(f"âš ï¸  æ— æ³•å¯¼å…¥ ImageSharpener: {e}")
            print("âš ï¸  é”åŒ–åŠŸèƒ½å°†ä¸å¯ç”¨")
            return None
    
    def hybrid_denoise_v2_enhanced(self, image: np.ndarray, noise_types: List[str] = None, 
                                 intensities: List[float] = None, sharpen_strength: int = 10) -> np.ndarray:
        """
        å¢å¼ºçš„æ··åˆå»å™ªæ–¹æ³• V2 - åœ¨ V1 åŸºç¡€ä¸ŠåŠ å…¥é”åŒ–å¤„ç†
        
        å‚æ•°:
            image: è¾“å…¥å™ªå£°å›¾åƒ
            noise_types: å™ªå£°ç±»å‹åˆ—è¡¨
            intensities: å™ªå£°å¼ºåº¦åˆ—è¡¨  
            sharpen_strength: é”åŒ–å¼ºåº¦ (1-20)ï¼Œé»˜è®¤+10
        
        è¿”å›:
            å»å™ªå¹¶é”åŒ–åçš„å›¾åƒ
        """
        print(f"ğŸ”§ å¼€å§‹ V2 æ··åˆå»å™ª (é”åŒ–å¼ºåº¦: +{sharpen_strength})")
        
    def hybrid_denoise_v2_enhanced(self, image: np.ndarray, noise_types: List[str] = None, 
                             intensities: List[float] = None, sharpen_strength: int = 10) -> np.ndarray:
        """
        å¢å¼ºçš„æ··åˆå»å™ªæ–¹æ³• V2 - å…ˆé”åŒ–å†DnCNN
        
        å‚æ•°:
            image: è¾“å…¥å™ªå£°å›¾åƒ
            noise_types: å™ªå£°ç±»å‹åˆ—è¡¨
            intensities: å™ªå£°å¼ºåº¦åˆ—è¡¨  
            sharpen_strength: é”åŒ–å¼ºåº¦ (1-20)ï¼Œé»˜è®¤+10
        
        è¿”å›:
            å»å™ªå¹¶é”åŒ–åçš„å›¾åƒ
        """
        print(f"ğŸ”§ å¼€å§‹ V2 æ··åˆå»å™ª (å…ˆé”åŒ–å†DnCNN, é”åŒ–å¼ºåº¦: +{sharpen_strength})")
    
        try:
            # æ­¥éª¤1: å…ˆå¯¹å™ªå£°å›¾åƒè¿›è¡Œé”åŒ–é¢„å¤„ç†
            sharpened_input = image
            if self.image_sharpener is not None:
                print("1/4 è¾“å…¥å›¾åƒé”åŒ–é¢„å¤„ç†...")
                sharpened_input = self._apply_sharpening(image, sharpen_strength)
            else:
                print("1/4 è·³è¿‡è¾“å…¥é”åŒ– (é”åŒ–å™¨ä¸å¯ç”¨)")
            
            # æ­¥éª¤2: æ·±åº¦å­¦ä¹ å»å™ªï¼ˆå¯¹é”åŒ–åçš„å›¾åƒï¼‰
            print("2/4 æ·±åº¦å­¦ä¹ å»å™ª...")
            dl_denoised = self.deep_learning_denoise(sharpened_input)
            
            # æ­¥éª¤3: ä¼ ç»Ÿæ–¹æ³•ä¼˜åŒ–ç»†èŠ‚
            print("3/4 ä¼ ç»Ÿæ–¹æ³•ä¼˜åŒ–...")
            traditional_refined = self.traditional_denoiser.wavelet_bilateral_hybrid(dl_denoised)
            
            # æ­¥éª¤4: æœ€ç»ˆè´¨é‡ä¼˜åŒ–
            print("4/4 æœ€ç»ˆè´¨é‡ä¼˜åŒ–...")
            final_result = self._post_processing_optimization(traditional_refined, image)
            
            print("âœ… V2 æ··åˆå»å™ªå®Œæˆ (å…ˆé”åŒ–ç­–ç•¥)")
            return final_result
            
        except Exception as e:
            print(f"âŒ V2 æ··åˆå»å™ªå¤±è´¥: {e}, ä½¿ç”¨åŸºç¡€æ–¹æ³•")
            return self.hybrid_denoise_v1(image)
    
    def _apply_sharpening(self, image: np.ndarray, strength: int) -> np.ndarray:
        """
        åº”ç”¨é”åŒ–å¤„ç†
        
        å‚æ•°:
            image: è¾“å…¥å›¾åƒ
            strength: é”åŒ–å¼ºåº¦ (1-20)
        
        è¿”å›:
            é”åŒ–åçš„å›¾åƒ
        """
        try:
            # æ ‡å‡†åŒ–å¼ºåº¦å€¼
            strength = max(1, min(20, strength))
            
            # æ ¹æ®å¼ºåº¦é€‰æ‹©é”åŒ–ç­–ç•¥
            if strength <= 5:
                # è½»åº¦é”åŒ– - ä¿æŒè‡ªç„¶æ„Ÿ
                return self.image_sharpener.adaptive_sharpen(
                    image, 
                    method='unsharp',
                    strength=0.8 + strength * 0.1,  # 0.9 - 1.3
                    sigma=1.2,
                    threshold=8
                )
            elif strength <= 10:
                # ä¸­åº¦é”åŒ– - å¹³è¡¡å¢å¼º
                result = self.image_sharpener.adaptive_sharpen(
                    image,
                    method='unsharp', 
                    strength=1.3 + (strength - 5) * 0.14,  # 1.3 - 2.0
                    sigma=1.0,
                    threshold=5
                )
                return result
            elif strength <= 15:
                # å¼ºåº¦é”åŒ– - æ˜¾è‘—å¢å¼º
                # ç¬¬ä¸€è½®: éé”åŒ–æ©è”½
                sharpened = self.image_sharpener.unsharp_mask(
                    image,
                    strength=2.0 + (strength - 10) * 0.2,  # 2.0 - 3.0
                    sigma=0.8,
                    threshold=3
                )
                # ç¬¬äºŒè½®: æ‹‰æ™®æ‹‰æ–¯å¢å¼ºè¾¹ç¼˜
                return self.image_sharpener.laplacian_sharpen(sharpened, strength=0.15)
            else:
                # è¶…å¼ºé”åŒ– - å¤šé‡å¤„ç†
                # ç¬¬ä¸€è½®: å¼ºéé”åŒ–æ©è”½
                sharpened = self.image_sharpener.unsharp_mask(
                    image,
                    strength=3.0,
                    sigma=0.6, 
                    threshold=1
                )
                # ç¬¬äºŒè½®: æ‹‰æ™®æ‹‰æ–¯é”åŒ–
                sharpened = self.image_sharpener.laplacian_sharpen(sharpened, strength=0.25)
                # ç¬¬ä¸‰è½®: å¼•å¯¼æ»¤æ³¢é”åŒ–
                return self.image_sharpener.guided_sharpen(sharpened, strength=1.2)
                
        except Exception as e:
            print(f"âš ï¸  é”åŒ–å¤„ç†å¤±è´¥: {e}, è¿”å›æœªé”åŒ–å›¾åƒ")
            return image
    
    def _post_processing_optimization(self, processed_image: np.ndarray, original_image: np.ndarray) -> np.ndarray:
        """
        åå¤„ç†ä¼˜åŒ– - ç¡®ä¿æœ€ç»ˆè´¨é‡
        
        å‚æ•°:
            processed_image: å¤„ç†åçš„å›¾åƒ
            original_image: åŸå§‹å™ªå£°å›¾åƒ
        
        è¿”å›:
            ä¼˜åŒ–åçš„å›¾åƒ
        """
        try:
            # æ£€æŸ¥å›¾åƒè´¨é‡æŒ‡æ ‡
            current_psnr = calculate_psnr(original_image, processed_image)
            
            # å¦‚æœè´¨é‡è¾ƒå·®ï¼Œåº”ç”¨è½»åº¦é™å™ª
            if current_psnr < 25:  # PSNR é˜ˆå€¼
                print("ğŸ”„ æ£€æµ‹åˆ°è´¨é‡è¾ƒä½ï¼Œåº”ç”¨è½»åº¦ä¼˜åŒ–...")
                optimized = cv2.bilateralFilter(processed_image, 5, 25, 25)
                return optimized
            
            return processed_image
            
        except Exception as e:
            print(f"âš ï¸  åå¤„ç†ä¼˜åŒ–å¤±è´¥: {e}")
            return processed_image
    
    def hybrid_denoise_v2(self, image: np.ndarray, noise_types: List[str] = None, 
                         intensities: List[float] = None) -> np.ndarray:
        """
        ä¿æŒå‘åå…¼å®¹çš„ V2 æ–¹æ³• - é»˜è®¤ä½¿ç”¨+10é”åŒ–å¼ºåº¦
        
        å‚æ•°:
            image: è¾“å…¥å›¾åƒ
            noise_types: å™ªå£°ç±»å‹åˆ—è¡¨
            intensities: å™ªå£°å¼ºåº¦åˆ—è¡¨
            
        è¿”å›:
            å»å™ªåçš„å›¾åƒ
        """
        return self.hybrid_denoise_v2_enhanced(
            image, 
            noise_types, 
            intensities, 
            sharpen_strength=10  # é»˜è®¤+10é”åŒ–
        )
    
    def compare_sharpening_effects(self, image: np.ndarray, noise_types: List[str] = None,
                                 intensities: List[float] = None) -> Dict[str, np.ndarray]:
        """
        æ¯”è¾ƒä¸åŒé”åŒ–å¼ºåº¦çš„æ•ˆæœ
        
        å‚æ•°:
            image: è¾“å…¥å›¾åƒ
            noise_types: å™ªå£°ç±»å‹åˆ—è¡¨
            intensities: å™ªå£°å¼ºåº¦åˆ—è¡¨
            
        è¿”å›:
            ä¸åŒé”åŒ–å¼ºåº¦çš„ç»“æœå­—å…¸
        """
        results = {}
        
        print("\nğŸ” æ¯”è¾ƒä¸åŒé”åŒ–å¼ºåº¦æ•ˆæœ:")
        print("-" * 40)
        
        # æµ‹è¯•ä¸åŒé”åŒ–å¼ºåº¦
        sharpen_strengths = [5, 10, 15, 20]
        
        for strength in sharpen_strengths:
            print(f"æµ‹è¯•é”åŒ–å¼ºåº¦ +{strength}...")
            result = self.hybrid_denoise_v2_enhanced(
                image, noise_types, intensities, sharpen_strength=strength
            )
            results[f'V2_Sharpness_{strength}'] = result
        
        # åŒ…å«æ— é”åŒ–ç‰ˆæœ¬ä½œä¸ºå¯¹æ¯”
        print("æµ‹è¯•æ— é”åŒ–ç‰ˆæœ¬...")
        no_sharpen_result = self.hybrid_denoise_v1(image)
        results['V1_No_Sharpening'] = no_sharpen_result
        
        return results
    

    def hybrid_denoise_v3(self, image):
        """æ··åˆå»å™ªæ–¹æ³•3"""
        dl_result = self.deep_learning_denoise(image)
        wavelet_result = self.traditional_denoiser.wavelet_denoise_robust(image)
        bilateral_result = self.traditional_denoiser.bilateral_denoise_basic(image)
        
        # åŠ æƒèåˆ
        fused = cv2.addWeighted(dl_result, 0.5, wavelet_result, 0.3, 0)
        fused = cv2.addWeighted(fused, 0.7, bilateral_result, 0.3, 0)
        
        return fused
    
    def wavelet_bilateral_hybrid(self, image):
        """å°æ³¢åŒè¾¹æ··åˆ"""
        return self.traditional_denoiser.wavelet_bilateral_hybrid(image)

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # æµ‹è¯•ä¿®å¤åçš„ä»£ç 
    denoiser = AdvancedDenoiser()
    
    # åˆ›å»ºæµ‹è¯•å›¾åƒ
    test_image = np.random.randint(0, 255, (256, 256, 3), dtype=np.uint8)
    
    # æµ‹è¯•å„ç§æ–¹æ³•
    methods = {
        'Wavelet': denoiser.traditional_denoiser.wavelet_denoise_robust,
        'Bilateral': denoiser.traditional_denoiser.bilateral_denoise_adaptive,
        'DnCNN': denoiser.deep_learning_denoise,
        'Hybrid_V1': denoiser.hybrid_denoise_v1,
        'Hybrid_V2': denoiser.hybrid_denoise_v2,
        'Hybrid_V3': denoiser.hybrid_denoise_v3,
    }
    
    for name, method in methods.items():
        try:
            result = method(test_image)
            psnr = calculate_psnr(test_image, result)
            ssim_val = calculate_ssim(test_image, result)
            print(f"{name}: PSNR={psnr:.2f}dB, SSIM={ssim_val:.4f}")
        except Exception as e:
            print(f"{name} å¤±è´¥: {e}")

