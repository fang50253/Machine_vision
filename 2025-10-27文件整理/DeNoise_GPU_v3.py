# DeNoise_GPU 2025-10-27ç‰ˆæœ¬æ›´æ–°è¯´æ˜ï¼š
# åˆ é™¤äº†é”åŒ–ç›¸å…³ä»£ç 

import cv2
import numpy as np
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import os
import glob
import pandas as pd
from datetime import datetime
import time

# è®¾ç½®éšæœºç§å­ä»¥ä¿è¯ç»“æœå¯é‡ç°
np.random.seed(42)
torch.manual_seed(42)

MAX_Pixel = 1024
NUM_Laters = 17

class ImprovedDnCNN(nn.Module):
    """æ”¹è¿›çš„DnCNNæ¨¡å‹ - NUM_Laterså±‚æ·±åº¦"""
    
    def __init__(self, channels=3, num_layers=NUM_Laters, num_features=64):
        super(ImprovedDnCNN, self).__init__()
        
        layers = []
        # ç¬¬ä¸€å±‚
        layers.append(nn.Conv2d(channels, num_features, kernel_size=3, padding=1))
        layers.append(nn.ReLU(inplace=True))
        
        # ä¸­é—´å±‚
        for _ in range(num_layers - 2):
            layers.append(nn.Conv2d(num_features, num_features, kernel_size=3, padding=1))
            layers.append(nn.BatchNorm2d(num_features))
            layers.append(nn.ReLU(inplace=True))
        
        # æœ€åä¸€å±‚
        layers.append(nn.Conv2d(num_features, channels, kernel_size=3, padding=1))
        
        self.dncnn = nn.Sequential(*layers)
    
    def forward(self, x):
        out = self.dncnn(x)
        return x - out

class TraditionalDenoiser:
    """ä¼ ç»Ÿå›¾åƒå»å™ªæ–¹æ³•"""
    
    @staticmethod
    def wavelet_denoise(image, wavelet='db4', level=2, threshold=0.1):
        """å°æ³¢å˜æ¢å»å™ª"""
        try:
            import pywt
            image_float = image.astype(np.float32) / 255.0
            
            if len(image.shape) == 3:
                denoised = np.zeros_like(image_float)
                for i in range(3):
                    coeffs = pywt.wavedec2(image_float[:,:,i], wavelet, level=level)
                    coeffs_thresh = []
                    coeffs_thresh.append(coeffs[0])
                    for level_coeff in coeffs[1:]:
                        thresh_coeff = []
                        for detail in level_coeff:
                            thresh_detail = pywt.threshold(detail, threshold * np.max(np.abs(detail)), 'soft')
                            thresh_coeff.append(thresh_detail)
                        coeffs_thresh.append(tuple(thresh_coeff))
                    
                    denoised[:,:,i] = pywt.waverec2(coeffs_thresh, wavelet)
            else:
                coeffs = pywt.wavedec2(image_float, wavelet, level=level)
                coeffs_thresh = []
                coeffs_thresh.append(coeffs[0])
                for level_coeff in coeffs[1:]:
                    thresh_coeff = []
                    for detail in level_coeff:
                        thresh_detail = pywt.threshold(detail, threshold * np.max(np.abs(detail)), 'soft')
                        thresh_coeff.append(thresh_detail)
                    coeffs_thresh.append(tuple(thresh_coeff))
                
                denoised = pywt.waverec2(coeffs_thresh, wavelet)
            
            denoised = np.clip(denoised, 0, 1)
            return (denoised * 255).astype(np.uint8)
            
        except ImportError:
            print("PyWaveletsæœªå®‰è£…ï¼Œä½¿ç”¨ä¸­å€¼æ»¤æ³¢ä»£æ›¿")
            return cv2.medianBlur(image, 5)
        except Exception as e:
            print(f"å°æ³¢å»å™ªå‡ºé”™: {e}ï¼Œä½¿ç”¨ä¸­å€¼æ»¤æ³¢ä»£æ›¿")
            return cv2.medianBlur(image, 5)
    
    @staticmethod
    def median_denoise(image, kernel_size=5):
        return cv2.medianBlur(image, kernel_size)
    
    @staticmethod
    def bilateral_denoise(image, d=9, sigma_color=75, sigma_space=75):
        return cv2.bilateralFilter(image, d, sigma_color, sigma_space)
    
    @staticmethod
    def gaussian_denoise(image, kernel_size=5, sigma=1.0):
        return cv2.GaussianBlur(image, (kernel_size, kernel_size), sigma)

class AdvancedDenoiser:
    def __init__(self, model_path=None):
        self.traditional_denoiser = TraditionalDenoiser()
        self.model = None
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ä½¿ç”¨è®¾å¤‡: {self.device}")
        self.load_pretrained_model(model_path)
        # æ·»åŠ æ¨¡å‹è¯Šæ–­
        self.diagnose_model()
    
    def load_pretrained_model(self, model_path=None):
        self.model = ImprovedDnCNN(channels=3, num_layers=NUM_Laters, num_features=64)
        self.model.to(self.device)
        
        if model_path and os.path.exists(model_path):
            try:
                # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
                file_size = os.path.getsize(model_path) / 1024 / 1024  # MB
                print(f"æ¨¡å‹æ–‡ä»¶å¤§å°: {file_size:.2f} MB")
                
                # åŠ è½½æ¨¡å‹
                state_dict = torch.load(model_path, map_location=self.device)
                self.model.load_state_dict(state_dict)
                self.model.eval()  # ç¡®ä¿è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
                
                # æ£€æŸ¥æ¨¡å‹å‚æ•°
                total_params = sum(p.numel() for p in self.model.parameters())
                print(f"æ¨¡å‹å‚æ•°æ€»æ•°: {total_params:,}")
                
                print(f"âœ… é¢„è®­ç»ƒæ¨¡å‹åŠ è½½æˆåŠŸ: {os.path.basename(model_path)}")
                
            except Exception as e:
                print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
                print("ä½¿ç”¨éšæœºåˆå§‹åŒ–çš„æ¨¡å‹")
        else:
            print("âŒ æœªæä¾›æ¨¡å‹è·¯å¾„æˆ–æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨éšæœºåˆå§‹åŒ–çš„æ¨¡å‹")
    
    def diagnose_model(self):
        """è¯Šæ–­æ¨¡å‹çŠ¶æ€"""
        print(f"\nğŸ” æ¨¡å‹è¯Šæ–­ä¿¡æ¯:")
        print(f"   è®¾å¤‡: {self.device}")
        
        if self.model is not None:
            # æ£€æŸ¥æ¨¡å‹æ˜¯å¦åœ¨evalæ¨¡å¼
            print(f"   è®­ç»ƒæ¨¡å¼: {'è®­ç»ƒ' if self.model.training else 'è¯„ä¼°'}")
            
            # æ£€æŸ¥å‚æ•°æ˜¯å¦å…¨ä¸ºé›¶ï¼ˆæœªè®­ç»ƒï¼‰
            with torch.no_grad():
                sample_input = torch.randn(1, 3, 64, 64).to(self.device)
                output = self.model(sample_input)
                output_range = output.abs().max().item()
                print(f"   æµ‹è¯•è¾“å‡ºèŒƒå›´: {output_range:.6f}")
    
    def preprocess_image(self, image):
        """æ”¹è¿›çš„é¢„å¤„ç† - ç¡®ä¿ä¸ç¬¬ä¸€ä¸ªä»£ç ä¸€è‡´"""
        # ç¡®ä¿å›¾åƒæ˜¯uint8ç±»å‹
        if image.dtype != np.uint8:
            image = image.astype(np.uint8)
        
        # è½¬æ¢ä¸ºtensorå¹¶å½’ä¸€åŒ–
        image_tensor = torch.from_numpy(image.transpose(2, 0, 1)).float() / 255.0
        return image_tensor.unsqueeze(0).to(self.device)
    
    def postprocess_image(self, tensor):
        """æ”¹è¿›çš„åå¤„ç†"""
        image = tensor.squeeze(0).cpu().detach().numpy()
        image = image.transpose(1, 2, 0)
        # ç¡®ä¿æ•°å€¼èŒƒå›´æ­£ç¡®
        image = np.clip(image, 0, 1)
        image = (image * 255).astype(np.uint8)
        return image
    
    def deep_learning_denoise(self, image):
        if self.model is None:
            print("é”™è¯¯ï¼šæ¨¡å‹æœªåˆå§‹åŒ–")
            return image
        
        self.model.eval()
        with torch.no_grad():
            input_tensor = self.preprocess_image(image)
            output_tensor = self.model(input_tensor)
            denoised_image = self.postprocess_image(output_tensor)
        
        return denoised_image
    
    def test_model_effectiveness(self, test_image):
        """æµ‹è¯•æ¨¡å‹æœ‰æ•ˆæ€§"""
        print("\nğŸ§ª æµ‹è¯•æ¨¡å‹æœ‰æ•ˆæ€§...")
        
        # æ·»åŠ å¼ºå™ªå£°
        strong_noise = np.random.normal(0, 50, test_image.shape).astype(np.float32)
        noisy_test = np.clip(test_image.astype(np.float32) + strong_noise, 0, 255).astype(np.uint8)
        
        # ä½¿ç”¨æ·±åº¦å­¦ä¹ å»å™ª
        dl_denoised = self.deep_learning_denoise(noisy_test)
        
        # ä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•å¯¹æ¯”
        median_denoised = self.traditional_denoiser.median_denoise(noisy_test)
        
        # è®¡ç®—PSNR
        original_psnr = calculate_psnr(test_image, noisy_test)
        dl_psnr = calculate_psnr(test_image, dl_denoised)
        median_psnr = calculate_psnr(test_image, median_denoised)
        
        print(f"ğŸ“Š å™ªå£°å›¾åƒ PSNR: {original_psnr:.2f} dB")
        print(f"ğŸ“Š æ·±åº¦å­¦ä¹  PSNR: {dl_psnr:.2f} dB")
        print(f"ğŸ“Š ä¸­å€¼æ»¤æ³¢ PSNR: {median_psnr:.2f} dB")
        
        improvement = dl_psnr - original_psnr
        print(f"ğŸ“ˆ æ·±åº¦å­¦ä¹ æ”¹è¿›: {improvement:+.2f} dB")
        
        if improvement < 1.0:
            print("âš ï¸  è­¦å‘Š: æ·±åº¦å­¦ä¹ æ¨¡å‹æ•ˆæœä¸ä½³ï¼")
            return False
        else:
            print("âœ… æ·±åº¦å­¦ä¹ æ¨¡å‹å·¥ä½œæ­£å¸¸")
            return True

    def hybrid_denoise_v1(self, image):
        traditional_denoised = self.traditional_denoiser.bilateral_denoise(image)
        final_denoised = self.deep_learning_denoise(traditional_denoised)
        return final_denoised
    
    def hybrid_denoise_v2(self, image):
        wavelet_denoised = self.traditional_denoiser.wavelet_denoise(image)
        bilateral_denoised = self.traditional_denoiser.bilateral_denoise(image)
        dl_denoised = self.deep_learning_denoise(image)
        
        alpha = 0.3
        beta = 0.7
        
        traditional_avg = cv2.addWeighted(wavelet_denoised, 0.5, bilateral_denoised, 0.5, 0)
        hybrid_result = cv2.addWeighted(traditional_avg, alpha, dl_denoised, beta, 0)
        
        return hybrid_result

def get_model_path():
    possible_dirs = ["improved_models", "trained_models", "models"]
    model_files = []
    
    for model_dir in possible_dirs:
        if os.path.exists(model_dir):
            files = [f for f in os.listdir(model_dir) if f.endswith('.pth') and 'best' in f]
            model_files.extend([os.path.join(model_dir, f) for f in files])
    
    if model_files:
        print("\nå‘ç°ä»¥ä¸‹æ¨¡å‹æ–‡ä»¶ï¼š")
        for i, model_file in enumerate(model_files, 1):
            print(f"{i}. {model_file}")
        print(f"{len(model_files) + 1}. ä¸ä½¿ç”¨æ¨¡å‹ï¼ˆéšæœºåˆå§‹åŒ–ï¼‰")
        print(f"{len(model_files) + 2}. æ‰‹åŠ¨è¾“å…¥æ¨¡å‹è·¯å¾„")
        
        try:
            choice = int(input("\nè¯·é€‰æ‹©æ¨¡å‹æ–‡ä»¶: ").strip())
            if 1 <= choice <= len(model_files):
                return model_files[choice-1]
            elif choice == len(model_files) + 1:
                return None
            elif choice == len(model_files) + 2:
                manual_path = input("è¯·è¾“å…¥æ¨¡å‹æ–‡ä»¶è·¯å¾„: ").strip()
                manual_path = manual_path.strip('"\'')
                return manual_path if os.path.exists(manual_path) else None
        except ValueError:
            print("æ— æ•ˆé€‰æ‹©ï¼Œå°†ä¸ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ã€‚")
    
    else:
        print("\næœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶ï¼Œå°†ä½¿ç”¨éšæœºåˆå§‹åŒ–çš„æ¨¡å‹ã€‚")
        print("è¯·å…ˆè¿è¡Œè®­ç»ƒç¨‹åºæ¥è®­ç»ƒæ¨¡å‹ã€‚")
    
    return None

def add_mixed_noise(image, noise_types=None, intensities=None):
    """æ·»åŠ æ··åˆå™ªå£°"""
    if noise_types is None:
        noise_types = ['gaussian', 'salt_pepper']
    if intensities is None:
        intensities = [25, 25]
    
    noisy_image = image.copy().astype(np.float32)
    
    for noise_type, intensity in zip(noise_types, intensities):
        if noise_type == 'gaussian':
            noise = np.random.normal(0, intensity, image.shape).astype(np.float32)
            noisy_image = noisy_image + noise
            
        elif noise_type == 'salt_pepper':
            amount = intensity / 200.0
            salt_mask = np.random.random(image.shape[:2]) < amount
            pepper_mask = np.random.random(image.shape[:2]) < amount
            noisy_image[salt_mask] = 255
            noisy_image[pepper_mask] = 0
            
        elif noise_type == 'poisson':
            # æ³Šæ¾å™ªå£°
            noise = np.random.poisson(noisy_image * intensity / 255.0)
            noisy_image = noise * (255.0 / intensity)
            
        elif noise_type == 'speckle':
            # æ•£æ–‘å™ªå£°
            speckle = np.random.randn(*image.shape) * intensity * 0.01
            noisy_image = noisy_image + noisy_image * speckle
    
    noisy_image = np.clip(noisy_image, 0, 255)
    return noisy_image.astype(np.uint8)

def add_noise_debug(image, noise_type='gaussian', intensity=25):
    """è°ƒè¯•ç‰ˆçš„å™ªå£°æ·»åŠ å‡½æ•°ï¼Œç¡®ä¿å™ªå£°è¢«æ­£ç¡®æ·»åŠ """
    print(f"æ·»åŠ å™ªå£°å‰ - å›¾åƒèŒƒå›´: [{image.min()}, {image.max()}], å½¢çŠ¶: {image.shape}")
    
    noisy_image = image.copy().astype(np.float32)
    
    if noise_type == 'gaussian':
        noise = np.random.normal(0, intensity, image.shape).astype(np.float32)
        print(f"é«˜æ–¯å™ªå£° - å‡å€¼: {noise.mean():.2f}, æ ‡å‡†å·®: {noise.std():.2f}")
        noisy_image = noisy_image + noise
        
    elif noise_type == 'salt_pepper':
        amount = intensity / 500.0
        print(f"æ¤’ç›å™ªå£° - å¼ºåº¦: {intensity}, æ¯”ä¾‹: {amount:.4f}")
        salt_mask = np.random.random(image.shape[:2]) < amount
        noisy_image[salt_mask] = 255
        pepper_mask = np.random.random(image.shape[:2]) < amount
        noisy_image[pepper_mask] = 0
    
    noisy_image = np.clip(noisy_image, 0, 255).astype(np.uint8)
    print(f"æ·»åŠ å™ªå£°å - å›¾åƒèŒƒå›´: [{noisy_image.min()}, {noisy_image.max()}]")
    
    noise_diff = noisy_image.astype(np.float32) - image.astype(np.float32)
    print(f"å™ªå£°å·®å¼‚ - å‡å€¼: {noise_diff.mean():.2f}, æ ‡å‡†å·®: {noise_diff.std():.2f}")
    
    return noisy_image

def calculate_psnr(original, denoised):
    original_float = original.astype(np.float64)
    denoised_float = denoised.astype(np.float64)
    
    mse = np.mean((original_float - denoised_float) ** 2)
    if mse == 0:
        return float('inf')
    max_pixel = 255.0
    psnr = 20 * np.log10(max_pixel / np.sqrt(mse))
    return psnr

def calculate_ssim(original, denoised):
    try:
        from skimage.metrics import structural_similarity as compare_ssim
        if len(original.shape) == 3:
            original_gray = cv2.cvtColor(original, cv2.COLOR_BGR2GRAY)
            denoised_gray = cv2.cvtColor(denoised, cv2.COLOR_BGR2GRAY)
        else:
            original_gray = original
            denoised_gray = denoised
        return compare_ssim(original_gray, denoised_gray, data_range=255)
    except ImportError:
        return 0

def normalize_psnr(psnr_values):
    """æ ‡å‡†åŒ–PSNRå€¼åˆ°0-1èŒƒå›´"""
    if not psnr_values:
        return []
    
    min_psnr = min(psnr_values)
    max_psnr = max(psnr_values)
    
    if max_psnr == min_psnr:
        return [1.0] * len(psnr_values)
    
    normalized = [(psnr - min_psnr) / (max_psnr - min_psnr) for psnr in psnr_values]
    return normalized

def get_input_mode():
    """è·å–è¾“å…¥æ¨¡å¼é€‰æ‹©"""
    print("\n" + "="*50)
    print("é«˜çº§å›¾åƒå»å™ªæµ‹è¯•ç¨‹åº")
    print("="*50)
    print("è¯·é€‰æ‹©å¤„ç†æ¨¡å¼ï¼š")
    print("1. å•å¼ å›¾åƒå¤„ç†")
    print("2. æ‰¹é‡æ–‡ä»¶å¤¹å¤„ç†")
    print("3. é€€å‡ºç¨‹åº")
    
    while True:
        choice = input("\nè¯·é€‰æ‹© (1/2/3): ").strip()
        if choice in ['1', '2', '3']:
            return choice
        else:
            print("æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥ã€‚")

def get_folder_path():
    """è·å–æ–‡ä»¶å¤¹è·¯å¾„ - ä¿®å¤ç‰ˆ"""
    while True:
        folder_path = input("\nè¯·è¾“å…¥åŒ…å«å›¾åƒçš„æ–‡ä»¶å¤¹è·¯å¾„: ").strip().strip('"\'')
        
        if not os.path.exists(folder_path):
            print(f"é”™è¯¯ï¼šæ–‡ä»¶å¤¹ '{folder_path}' ä¸å­˜åœ¨ï¼Œè¯·é‡æ–°è¾“å…¥ã€‚")
            continue
            
        # æ”¹è¿›çš„å›¾åƒæ–‡ä»¶æœç´¢é€»è¾‘
        image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif', '.JPG', '.JPEG', '.PNG', '.BMP']
        image_files = []
        
        print(f"æ­£åœ¨æœç´¢æ–‡ä»¶å¤¹: {folder_path}")
        
        # æ–¹æ³•1: ä½¿ç”¨os.walké€’å½’æœç´¢
        for root, dirs, files in os.walk(folder_path):
            for file in files:
                file_lower = file.lower()
                if any(file_lower.endswith(ext) for ext in ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif']):
                    full_path = os.path.join(root, file)
                    image_files.append(full_path)
        
        # æ–¹æ³•2: å¦‚æœæ–¹æ³•1æ²¡æ‰¾åˆ°ï¼Œå°è¯•ç›´æ¥æœç´¢å½“å‰æ–‡ä»¶å¤¹
        if not image_files:
            print("å°è¯•ç›´æ¥æœç´¢å½“å‰æ–‡ä»¶å¤¹...")
            for file in os.listdir(folder_path):
                if os.path.isfile(os.path.join(folder_path, file)):
                    file_lower = file.lower()
                    if any(file_lower.endswith(ext) for ext in ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif']):
                        full_path = os.path.join(folder_path, file)
                        image_files.append(full_path)
        
        # æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
        print(f"æ‰¾åˆ°çš„æ–‡ä»¶æ€»æ•°: {len(os.listdir(folder_path))}")
        print(f"è¯†åˆ«å‡ºçš„å›¾åƒæ–‡ä»¶: {len(image_files)}")
        
        if not image_files:
            print(f"åœ¨æ–‡ä»¶å¤¹ '{folder_path}' ä¸­æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶ã€‚")
            print("æ”¯æŒçš„æ ¼å¼: JPG, JPEG, PNG, BMP, TIFF, TIF")
            
            # æ˜¾ç¤ºæ–‡ä»¶å¤¹å†…å®¹ä»¥ä¾¿è°ƒè¯•
            try:
                all_files = os.listdir(folder_path)
                print(f"\næ–‡ä»¶å¤¹å†…å®¹ ({len(all_files)} ä¸ªæ–‡ä»¶/æ–‡ä»¶å¤¹):")
                for i, item in enumerate(all_files[:10]):  # åªæ˜¾ç¤ºå‰10ä¸ª
                    item_path = os.path.join(folder_path, item)
                    if os.path.isfile(item_path):
                        print(f"  æ–‡ä»¶: {item}")
                    else:
                        print(f"  æ–‡ä»¶å¤¹: {item}/")
                if len(all_files) > 10:
                    print(f"  ... è¿˜æœ‰ {len(all_files) - 10} ä¸ªé¡¹")
            except Exception as e:
                print(f"æ— æ³•åˆ—å‡ºæ–‡ä»¶å¤¹å†…å®¹: {e}")
            
            continue
            
        # å»é‡å’Œæ’åº
        image_files = list(set(image_files))
        image_files.sort()
        
        print(f"\næ‰¾åˆ° {len(image_files)} ä¸ªå›¾åƒæ–‡ä»¶:")
        for i, file_path in enumerate(image_files[:5]):
            file_size = os.path.getsize(file_path) // 1024  # KB
            print(f"  {i+1}. {os.path.basename(file_path)} ({file_size} KB)")
        if len(image_files) > 5:
            print(f"  ... è¿˜æœ‰ {len(image_files) - 5} ä¸ªæ–‡ä»¶")
            
        confirm = input("\næ˜¯å¦å¤„ç†è¿™äº›æ–‡ä»¶ï¼Ÿ(y/n): ").strip().lower()
        if confirm in ['y', 'yes', '']:
            return folder_path, image_files
        else:
            print("è¯·é‡æ–°é€‰æ‹©æ–‡ä»¶å¤¹ã€‚")

def get_noise_settings():
    """è·å–å™ªå£°è®¾ç½®"""
    print("\nè¯·é€‰æ‹©å™ªå£°ç±»å‹ï¼š")
    print("1. é«˜æ–¯å™ªå£°")
    print("2. æ¤’ç›å™ªå£°") 
    print("3. æ··åˆå™ªå£° (é«˜æ–¯+æ¤’ç›)")
    print("4. è‡ªå®šä¹‰æ··åˆå™ªå£°")
    
    noise_choice = input("è¯·é€‰æ‹© (1/2/3/4): ").strip() or '1'
    
    if noise_choice == '2':
        noise_type = 'salt_pepper'
        noise_types = ['salt_pepper']
    elif noise_choice == '3':
        noise_type = 'mixed'
        noise_types = ['gaussian', 'salt_pepper']
    elif noise_choice == '4':
        print("\nå¯é€‰çš„å™ªå£°ç±»å‹: gaussian, salt_pepper, poisson, speckle")
        custom_types = input("è¯·è¾“å…¥å™ªå£°ç±»å‹(ç”¨é€—å·åˆ†éš”, å¦‚: gaussian,salt_pepper): ").strip()
        noise_types = [t.strip() for t in custom_types.split(',')]
        noise_type = 'custom_mixed'
    else:
        noise_type = 'gaussian'
        noise_types = ['gaussian']
    
    intensities = []
    if len(noise_types) == 1:
        try:
            intensity = int(input(f"è¯·è¾“å…¥å™ªå£°å¼ºåº¦ (1-100, é»˜è®¤25): ").strip() or '25')
            intensity = max(1, min(100, intensity))
            intensities = [intensity]
        except ValueError:
            intensities = [25]
            print("ä½¿ç”¨é»˜è®¤å™ªå£°å¼ºåº¦: 25")
    else:
        print("\nè¯·ä¸ºæ¯ç§å™ªå£°ç±»å‹è®¾ç½®å¼ºåº¦ (1-100):")
        for i, n_type in enumerate(noise_types):
            try:
                intensity = int(input(f"  {n_type} å™ªå£°å¼ºåº¦ (é»˜è®¤25): ").strip() or '25')
                intensity = max(1, min(100, intensity))
                intensities.append(intensity)
            except ValueError:
                intensities.append(25)
                print(f"  {n_type} ä½¿ç”¨é»˜è®¤å¼ºåº¦: 25")
    
    return noise_type, noise_types, intensities

def process_single_image():
    """å¤„ç†å•å¼ å›¾åƒ"""
    from Show import get_image_path, get_model_path, get_image_size_choice, load_and_process_image, denoise_program
    
    model_path = get_model_path()
    size_choice = get_image_size_choice()
    image_path = get_image_path()
    processed_image, original_fullsize = load_and_process_image(image_path, size_choice)
    
    noise_type, noise_types, intensities = get_noise_settings()
    
    print(f"\næ·»åŠ {noise_type}å™ªå£°...")
    if len(noise_types) == 1:
        noisy_image = add_noise_debug(processed_image, noise_type=noise_types[0], intensity=intensities[0])
    else:
        noisy_image = add_mixed_noise(processed_image, noise_types, intensities)
        print(f"æ··åˆå™ªå£°ç±»å‹: {noise_types}")
        print(f"å™ªå£°å¼ºåº¦: {intensities}")
    
    # ç»§ç»­åŸæœ‰çš„å•å¼ å›¾åƒå¤„ç†æµç¨‹
    denoiser = AdvancedDenoiser(model_path)
    
    print("å¼€å§‹å»å™ªå¤„ç†...")
    results = {}
    
    try:
        print("1/5 è¿›è¡Œå°æ³¢å»å™ª...")
        results['Wavelet'] = denoiser.traditional_denoiser.wavelet_denoise(noisy_image)
        
        print("2/5 è¿›è¡ŒåŒè¾¹æ»¤æ³¢...")
        results['Bilateral'] = denoiser.traditional_denoiser.bilateral_denoise(noisy_image)
        
        print("3/5 è¿›è¡Œæ·±åº¦å­¦ä¹ å»å™ª...")
        results['DnCNN'] = denoiser.deep_learning_denoise(noisy_image)
        
        print("4/5 è¿›è¡Œæ··åˆå»å™ªæ–¹æ³•1...")
        results['Hybrid V1'] = denoiser.hybrid_denoise_v1(noisy_image)
        
        print("5/5 è¿›è¡Œæ··åˆå»å™ªæ–¹æ³•2...")
        results['Hybrid V2'] = denoiser.hybrid_denoise_v2(noisy_image)
        
    except Exception as e:
        print(f"å»å™ªè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
    
    # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
    print("\n" + "="*50)
    print("å»å™ªæ•ˆæœè¯„ä¼°")
    print("="*50)
    
    noisy_psnr = calculate_psnr(processed_image, noisy_image)
    noisy_ssim = calculate_ssim(processed_image, noisy_image)
    
    print(f"å™ªå£°å›¾åƒ - PSNR: {noisy_psnr:.2f} dB")
    if noisy_ssim > 0:
        print(f"å™ªå£°å›¾åƒ - SSIM: {noisy_ssim:.3f}")
    
    print("\nå„æ–¹æ³•æ•ˆæœå¯¹æ¯”:")
    print("-" * 50)
    
    psnr_values = []
    for method, result in results.items():
        psnr = calculate_psnr(processed_image, result)
        ssim_val = calculate_ssim(processed_image, result)
        improvement_psnr = psnr - noisy_psnr
        
        psnr_values.append(psnr)
        
        if noisy_ssim > 0 and ssim_val > 0:
            improvement_ssim = ssim_val - noisy_ssim
            print(f"{method:12}: PSNR: {psnr:6.2f} dB (+{improvement_psnr:5.2f}) | SSIM: {ssim_val:.3f} (+{improvement_ssim:.3f})")
        else:
            print(f"{method:12}: PSNR: {psnr:6.2f} dB (+{improvement_psnr:5.2f})")
    
    # æ ‡å‡†åŒ–PSNRå€¼
    normalized_psnr = normalize_psnr(psnr_values)
    print("\næ ‡å‡†åŒ–PSNRå€¼ (0-1èŒƒå›´):")
    for i, (method, norm_psnr) in enumerate(zip(results.keys(), normalized_psnr)):
        print(f"{method:12}: {norm_psnr:.3f}")
    
    return {
        'noise_type': noise_type,
        'noise_intensities': intensities,
        'noisy_psnr': noisy_psnr,
        'noisy_ssim': noisy_ssim,
        'results': results,
        'psnr_values': psnr_values,
        'normalized_psnr': normalized_psnr
    }

def process_batch_images():
    """æ‰¹é‡å¤„ç†æ–‡ä»¶å¤¹ä¸­çš„å›¾åƒ"""
    folder_path, image_files = get_folder_path()
    model_path = get_model_path()
    noise_type, noise_types, intensities = get_noise_settings()
    
    # åˆ›å»ºç»“æœç›®å½•
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_dir = f"batch_results_{timestamp}"
    os.makedirs(output_dir, exist_ok=True)
    
    denoiser = AdvancedDenoiser(model_path)
    results_data = []
    
    print(f"\nå¼€å§‹æ‰¹é‡å¤„ç† {len(image_files)} å¼ å›¾åƒ...")
    print(f"å™ªå£°è®¾ç½®: {noise_type}, å¼ºåº¦: {intensities}")
    print(f"ç»“æœå°†ä¿å­˜åˆ°: {output_dir}")
    
    for i, image_path in enumerate(image_files, 1):
        print(f"\nå¤„ç†è¿›åº¦: {i}/{len(image_files)}")
        print(f"å½“å‰å›¾åƒ: {os.path.basename(image_path)}")
        
        try:
            # è¯»å–å›¾åƒ
            original_image = cv2.imread(image_path)
            if original_image is None:
                print(f"  è­¦å‘Š: æ— æ³•è¯»å–å›¾åƒ {image_path}ï¼Œè·³è¿‡")
                continue
                
            # è°ƒæ•´å°ºå¯¸
            h, w = original_image.shape[:2]
            if w > MAX_Pixel:
                scale = MAX_Pixel / w
                new_w = MAX_Pixel
                new_h = int(h * scale)
                processed_image = cv2.resize(original_image, (new_w, new_h))
            else:
                processed_image = original_image
            
            # æ·»åŠ å™ªå£°
            if len(noise_types) == 1:
                noisy_image = add_mixed_noise(processed_image, [noise_types[0]], [intensities[0]])
            else:
                noisy_image = add_mixed_noise(processed_image, noise_types, intensities)
            
            # åº”ç”¨å»å™ªæ–¹æ³•
            denoising_results = {}
            
            # å°æ³¢å»å™ª
            try:
                denoising_results['Wavelet'] = denoiser.traditional_denoiser.wavelet_denoise(noisy_image)
            except Exception as e:
                print(f"  å°æ³¢å»å™ªå¤±è´¥: {e}")
                denoising_results['Wavelet'] = processed_image
            
            # åŒè¾¹æ»¤æ³¢
            try:
                denoising_results['Bilateral'] = denoiser.traditional_denoiser.bilateral_denoise(noisy_image)
            except Exception as e:
                print(f"  åŒè¾¹æ»¤æ³¢å¤±è´¥: {e}")
                denoising_results['Bilateral'] = processed_image
            
            # æ·±åº¦å­¦ä¹ å»å™ª
            try:
                denoising_results['DnCNN'] = denoiser.deep_learning_denoise(noisy_image)
            except Exception as e:
                print(f"  æ·±åº¦å­¦ä¹ å»å™ªå¤±è´¥: {e}")
                denoising_results['DnCNN'] = processed_image
            
            # æ··åˆå»å™ªæ–¹æ³•1
            try:
                denoising_results['Hybrid_V1'] = denoiser.hybrid_denoise_v1(noisy_image)
            except Exception as e:
                print(f"  æ··åˆå»å™ªV1å¤±è´¥: {e}")
                denoising_results['Hybrid_V1'] = processed_image
            
            # æ··åˆå»å™ªæ–¹æ³•2
            try:
                denoising_results['Hybrid_V2'] = denoiser.hybrid_denoise_v2(noisy_image)
            except Exception as e:
                print(f"  æ··åˆå»å™ªV2å¤±è´¥: {e}")
                denoising_results['Hybrid_V2'] = processed_image
            
            # è®¡ç®—æŒ‡æ ‡
            noisy_psnr = calculate_psnr(processed_image, noisy_image)
            noisy_ssim = calculate_ssim(processed_image, noisy_image)
            
            method_psnrs = {}
            method_ssims = {}
            
            for method, result in denoising_results.items():
                method_psnrs[method] = calculate_psnr(processed_image, result)
                method_ssims[method] = calculate_ssim(processed_image, result)
            
            # æ ‡å‡†åŒ–PSNR
            psnr_values = list(method_psnrs.values())
            normalized_psnr = normalize_psnr(psnr_values)
            norm_psnr_dict = dict(zip(denoising_results.keys(), normalized_psnr))
            
            # ä¿å­˜ç»“æœæ•°æ®
            image_result = {
                'image_name': os.path.basename(image_path),
                'image_path': image_path,
                'image_size': f"{processed_image.shape[1]}x{processed_image.shape[0]}",
                'noise_type': noise_type,
                'noise_intensities': str(intensities),
                'noisy_psnr': noisy_psnr,
                'noisy_ssim': noisy_ssim
            }
            
            # æ·»åŠ å„æ–¹æ³•çš„æŒ‡æ ‡
            for method in denoising_results.keys():
                image_result[f'{method}_psnr'] = method_psnrs[method]
                image_result[f'{method}_ssim'] = method_ssims[method]
                image_result[f'{method}_psnr_norm'] = norm_psnr_dict[method]
            
            results_data.append(image_result)
            
            # ä¿å­˜å¤„ç†åçš„å›¾åƒ
            img_output_dir = os.path.join(output_dir, 'images', os.path.splitext(os.path.basename(image_path))[0])
            os.makedirs(img_output_dir, exist_ok=True)
            
            cv2.imwrite(os.path.join(img_output_dir, 'original.jpg'), processed_image)
            cv2.imwrite(os.path.join(img_output_dir, 'noisy.jpg'), noisy_image)
            
            for method, result in denoising_results.items():
                cv2.imwrite(os.path.join(img_output_dir, f'{method}.jpg'), result)
            
            print(f"  å®Œæˆ: PSNR={noisy_psnr:.2f}dB, å·²ä¿å­˜ç»“æœ")
            
        except Exception as e:
            print(f"  å¤„ç†å›¾åƒ {image_path} æ—¶å‡ºé”™: {e}")
            continue
    
    # ä¿å­˜CSVç»“æœ
    if results_data:
        df = pd.DataFrame(results_data)
        csv_path = os.path.join(output_dir, 'denoising_results.csv')
        df.to_csv(csv_path, index=False, encoding='utf-8-sig')
        
        # è®¡ç®—å¹³å‡æŒ‡æ ‡
        print(f"\n{'='*50}")
        print("æ‰¹é‡å¤„ç†å®Œæˆï¼")
        print(f"{'='*50}")
        print(f"å¤„ç†å›¾åƒæ•°é‡: {len(results_data)}")
        print(f"ç»“æœCSVæ–‡ä»¶: {csv_path}")
        print(f"å›¾åƒè¾“å‡ºç›®å½•: {output_dir}/images/")
        
        # æ˜¾ç¤ºå¹³å‡PSNR
        print("\nå„æ–¹æ³•å¹³å‡PSNR:")
        methods = ['Wavelet', 'Bilateral', 'DnCNN', 'Hybrid_V1', 'Hybrid_V2']
        for method in methods:
            avg_psnr = df[f'{method}_psnr'].mean()
            avg_norm_psnr = df[f'{method}_psnr_norm'].mean()
            print(f"  {method:12}: {avg_psnr:.2f} dB (æ ‡å‡†åŒ–: {avg_norm_psnr:.3f})")
    
    return results_data

def main():
    print("PyTorch ç‰ˆæœ¬:", torch.__version__)
    print("æ˜¯å¦æ”¯æŒ CUDA:", torch.cuda.is_available())
    print("å½“å‰è®¾å¤‡:", "cuda" if torch.cuda.is_available() else "cpu")
    print("\n" + "="*60)
    print("é«˜çº§å›¾åƒå»å™ªæµ‹è¯•ç³»ç»Ÿ - æ‰¹é‡å¤„ç†ç‰ˆ")
    print("="*60)
    
    while True:
        mode = get_input_mode()
        
        if mode == '1':
            print("\nè¿›å…¥å•å¼ å›¾åƒå¤„ç†æ¨¡å¼...")
            process_single_image()
            break
        elif mode == '2':
            print("\nè¿›å…¥æ‰¹é‡å¤„ç†æ¨¡å¼...")
            process_batch_images()
            break
        elif mode == '3':
            print("ç¨‹åºé€€å‡ºã€‚")
            break

if __name__ == "__main__":
    main()